{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgRzAemno6bp"
      },
      "source": [
        "# Fiche TP N° 02: Feature extraction and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wvAl3VjCo6bu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA1XHD15o6bw"
      },
      "source": [
        "### A. Préparation de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "qJvjT2LEo6bx",
        "outputId": "7f9650dd-7513-4fb3-f7a6-15a1c2cb9713"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EAP</td>\n",
              "      <td>['process', 'however', 'afforded', 'means', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HPL</td>\n",
              "      <td>['never', 'occurred', 'fumbling', 'might', 'me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EAP</td>\n",
              "      <td>['left', 'hand', 'gold', 'snuff', 'box', 'cape...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MWS</td>\n",
              "      <td>['lovely', 'spring', 'looked', 'windsor', 'ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HPL</td>\n",
              "      <td>['finding', 'nothing', 'else', 'even', 'gold',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MWS</td>\n",
              "      <td>['youth', 'passed', 'solitude', 'best', 'years...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>EAP</td>\n",
              "      <td>['astronomer', 'perhaps', 'point', 'took', 're...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>EAP</td>\n",
              "      <td>['surcingle', 'hung', 'ribands', 'body']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>EAP</td>\n",
              "      <td>['knew', 'could', 'say', 'stereotomy', 'withou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MWS</td>\n",
              "      <td>['confess', 'neither', 'structure', 'languages...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  author                                               text\n",
              "0    EAP  ['process', 'however', 'afforded', 'means', 'a...\n",
              "1    HPL  ['never', 'occurred', 'fumbling', 'might', 'me...\n",
              "2    EAP  ['left', 'hand', 'gold', 'snuff', 'box', 'cape...\n",
              "3    MWS  ['lovely', 'spring', 'looked', 'windsor', 'ter...\n",
              "4    HPL  ['finding', 'nothing', 'else', 'even', 'gold',...\n",
              "5    MWS  ['youth', 'passed', 'solitude', 'best', 'years...\n",
              "6    EAP  ['astronomer', 'perhaps', 'point', 'took', 're...\n",
              "7    EAP           ['surcingle', 'hung', 'ribands', 'body']\n",
              "8    EAP  ['knew', 'could', 'say', 'stereotomy', 'withou...\n",
              "9    MWS  ['confess', 'neither', 'structure', 'languages..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('spooky_treated.csv')\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocYPuGFqo6by"
      },
      "source": [
        "### B. Encodage de la variable à prédire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y1882KIko6by",
        "outputId": "6613017c-579d-4086-e07c-17e59d35b0e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EAP', 'HPL', 'MWS'], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['author'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['process', 'however', 'afforded', 'means', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['never', 'occurred', 'fumbling', 'might', 'me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['left', 'hand', 'gold', 'snuff', 'box', 'cape...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['lovely', 'spring', 'looked', 'windsor', 'ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['finding', 'nothing', 'else', 'even', 'gold',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  ['process', 'however', 'afforded', 'means', 'a...\n",
              "1  ['never', 'occurred', 'fumbling', 'might', 'me...\n",
              "2  ['left', 'hand', 'gold', 'snuff', 'box', 'cape...\n",
              "3  ['lovely', 'spring', 'looked', 'windsor', 'ter...\n",
              "4  ['finding', 'nothing', 'else', 'even', 'gold',..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X=data.drop(['author'],axis='columns')\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  author\n",
              "0    EAP\n",
              "1    HPL\n",
              "2    EAP\n",
              "3    MWS\n",
              "4    HPL"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y=data.drop(['text'],axis='columns')\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = pd.get_dummies(y, columns=['author'])\n",
        "y = y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_EAP</th>\n",
              "      <th>author_HPL</th>\n",
              "      <th>author_MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19574</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19575</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19576</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19577</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19578</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19579 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       author_EAP  author_HPL  author_MWS\n",
              "0               1           0           0\n",
              "1               0           1           0\n",
              "2               1           0           0\n",
              "3               0           0           1\n",
              "4               0           1           0\n",
              "...           ...         ...         ...\n",
              "19574           1           0           0\n",
              "19575           1           0           0\n",
              "19576           1           0           0\n",
              "19577           1           0           0\n",
              "19578           0           1           0\n",
              "\n",
              "[19579 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "y= y.rename(columns={'author_EAP': 'EAP', 'author_HPL': 'HPL','author_MWS':'MWS'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EAP  HPL  MWS\n",
              "0    1    0    0\n",
              "1    0    1    0\n",
              "2    1    0    0\n",
              "3    0    0    1\n",
              "4    0    1    0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVVkSWWCo6by"
      },
      "source": [
        "### C. Construction des bases d’entraînement et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C3vsf8Y2o6bz"
      },
      "outputs": [],
      "source": [
        "X_train_nos, X_test_nos, y_train_nos, y_test_nos = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=33,\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12583</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8381</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9920</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3391</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16640</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       EAP  HPL  MWS\n",
              "12583    0    0    1\n",
              "8381     0    1    0\n",
              "9920     0    1    0\n",
              "3391     0    0    1\n",
              "16640    0    1    0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_nos.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split with stratify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=33,\n",
        "                                                    stratify = y.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (19579, 1)\n",
            "X train shape: (15663, 1)\n",
            "X test shape: (3916, 1)\n",
            "Y shape: (19579, 3)\n",
            "Y train shape: (15663, 3)\n",
            "Y test shape: (3916, 3)\n"
          ]
        }
      ],
      "source": [
        "print('X shape:', X.shape)\n",
        "print('X train shape:', X_train.shape)\n",
        "print('X test shape:', X_test.shape)\n",
        "print('Y shape:', y.shape)\n",
        "print('Y train shape:', y_train.shape)\n",
        "print('Y test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "                                                    text  EAP  HPL  MWS\n",
            "11612  ['dress', 'trimmings', 'green', 'agraffas', 's...    1    0    0\n",
            "4926   ['true', 'spirit', 'reckless', 'enterprise', '...    0    0    1\n",
            "7067   ['iranon', 'singer', 'songs', 'said', 'heart',...    0    1    0\n",
            "7225   ['saw', 'indistinctly', 'much', 'effort', 'per...    1    0    0\n",
            "4389   ['least', 'long', 'period', 'inventor', 'lomba...    1    0    0\n",
            "\n",
            "Testing Set:\n",
            "                                                    text  EAP  HPL  MWS\n",
            "15931                              ['must', 'something']    0    1    0\n",
            "18593  ['urge', 'walk', 'gradually', 'changing', 'urg...    0    1    0\n",
            "5104   ['contrary', 'could', 'means', 'account', 'ove...    1    0    0\n",
            "15466                                        ['dispute']    0    0    1\n",
            "13473  ['reasoners', 'object', 'merely', 'show', 'bod...    1    0    0\n"
          ]
        }
      ],
      "source": [
        "# Display a sample of the training set\n",
        "print(\"Training Set:\")\n",
        "print(pd.concat([X_train, y_train], axis=1).head())\n",
        "\n",
        "# Display a sample of the testing set\n",
        "print(\"\\nTesting Set:\")\n",
        "print(pd.concat([X_test, y_test], axis=1).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABjYAAAJOCAYAAAAUHj4bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACbJklEQVR4nOzdfVwU5f7/8ffKnUi4CgorhYpGeG+mhWgnNBU10crKzCIrU8vSKO3GbtFTkHZSO1LeHfPe7JyT2I1FaqnlEbzrUGmmdbLUFDFDvAlB4fr94Y/5uiwgIIprr+fjsY9i5rMz18zO7ny8PtfM2IwxRgAAAAAAAAAAAG6gRnU3AAAAAAAAAAAAoLwobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobKDKpKen64477lCDBg3k7e0th8Oh22+/XWlpadXdtHL5+eefZbPZNHfuXGva3LlzZbPZ9PPPP5f53qK4olfNmjXlcDjUtWtXJSUlKSsry+U9CQkJstlsFWrjH3/8oYSEBK1Zs6ZC7ytpXY0bN1ZsbGyFlnM2ixcv1pQpU0qcZ7PZlJCQUKXrq4jx48erRYsWKiwsdGrTmS8/Pz81b95c48aN0/Hjxyu9rnfffVctW7aUr6+vbDabMjIyqmALzt2GDRt06623qmHDhvLx8VFwcLCioqI0evToSi2vvN+Z0o6Lso7n8n73zlVcXJxuueWW87oO4FxxjjntYjzHVOVvVdF+PNurS5cu57yuc9lfXbp0qZI2VMbJkyc1Y8YMXXvttQoICFCtWrXUqFEj3XzzzUpJSanUMhMTE7Vs2bIKved///uffHx8rBz30Ucflc1mU2ZmplPc77//rho1asjLy0vHjh1zmrd3717ZbDY98cQTkkr+Hr311ltO59gia9askc1m07///e8KtbsqVOZ3Ys+ePRoxYoSuuuoq+fr6KiAgQK1bt9bQoUO1Z88eK+7jjz8+r9/j0vZnSfmMVHI+V5nf1opYv369EhISdPjwYZd5F+K7N3v2bF1++eXnlAfj0kMechp5SNXlIVLZv/mNGzfWfffdVyXrqajjx49rwoQJatu2rWrXri1/f381bdpUAwYM0Nq1ayu8vMoe119++aV8fHz0yy+/SJJiY2Pl7++vU6dOOcX997//lc1mU4MGDUpchs1m09///ndJ0n333afGjRs7xZSWBxUdW5s3b65Qu8/06aefKiYmRiEhIfLx8VFISIi6dOmiV199tVxtqAr79u1TQkJCiX0yJf125Ofn66GHHlKDBg3k4eGhq6++WtL5PyYrmqNUtRtuuEHx8fHndR3njQGqwN///ndTo0YN07FjRzN//nyzdu1as2DBAtOxY0dTo0YNM3Xq1Opu4lnt2rXLSDJz5syxps2ZM8dIMrt27SrzvUVxc+bMMWlpaeaLL74w//73v018fLyx2+0mICDArFy50uk9e/bsMWlpaRVq48GDB40k89JLL1XofSWtq1GjRqZPnz4VWs7Z9OnTxzRq1KjEeWlpaWbPnj1Vur7y+vXXX42fn5/517/+5TRdkrn99ttNWlqaSUtLMytXrjTPP/+8qVGjhunfv3+l1pWVlWW8vLxM3759zZo1a0xaWpo5fvx4VWzGOfnoo49MjRo1zI033mjeeecds2bNGvPOO++Y0aNHm8svv7xSyyzpO5OVlWXS0tLMiRMnrGmlHRdlHc8lLed8+PHHH42np6f57LPPzut6gHPBOea0i/EcU5W/VUX7sei1dOlSI8mMHDnSafq2bdvOeV3nsr+2bdtWJW2ojDvvvNN4eXmZJ5980ixfvtysWrXKzJw50/Tv398MHz68Usv08/MzgwcPrtB7brnlFqfj+9///reRZN555x2nuKVLlxovLy/j5eVlPvnkE6d58+fPN5LMBx98YIwp+XvUsmVLEx0d7bL+1atXG0kuec2FUNHfiT179ph69eqZK6+80kybNs18/vnnJiUlxbzyyiumbdu2Zs2aNVbsI488Ys7nP09L258nTpwwaWlpJisry5pWWj5Xmd/WinjttddK/bfHhfjunTx50oSHh5sXX3zxvK4H7oU85DTykKrLQ4wp+zf/q6++Mj/++GOVrKciTp06ZTp16mT8/f3N+PHjTWpqqklNTTVTp041MTEx5q9//WuFl1mZ47qwsNBcc8015pFHHrGm/e1vfzOSXI71SZMmGT8/PyPJbN++3Wne+PHjjSTzzTffGGNO/9v3q6++coopLQ8q+t5v2rSp3O0+07Rp04wkc9ttt5n33nvPrF692syfP9889NBDpn379uVqQ1XYtGmTS59FkZJ+O6ZMmWIkmalTp5r169db++58H5MVyVHOhzVr1hgvLy/z/fffn9f1nA+eF6Z8gkvZf/7zH8XHx+umm25SSkqKPD3/77AaOHCgbr31Vj322GNq166dOnfufMHalZubq5o1a57XUVXFtWrVSh06dLD+vu222/T444/r+uuvV//+/fXDDz8oODhYknTFFVfoiiuuOK/t+eOPP1SrVq0Lsq6z6dixY7Wt+4033lCdOnXUv39/l3nBwcFObevevbt++eUXLVq0SCdOnFDNmjUrtK6dO3fq5MmTuueeexQdHX3ObZf+73M8FxMnTlRYWJg+/fRTl+/oxIkTz7WJlvr166t+/foXzXLOpmnTpurVq5deffVV3Xjjjed9fcC54BxTuuo6x1Tlb1Xx/Vg0+rJhw4Zlbt/Jkydls9mcftvP5lz2V4sWLSr93nOxa9cuvfvuu3rxxRc1btw4a3q3bt00dOhQpysyz6ft27dr2bJlSk1NtaZ16dJFNptNa9as0cCBA63pa9as0bXXXitjjFavXq1evXo5zatRo4ZuuOEGSRfmO1sdZs2apd9++00bN25UWFiYNf2WW27Rs88+W+nPzRijEydOyNfX95zb6OPj4/KdKC2fK/rNqw4X4rvn6emp4cOH669//auefvrpc84/cWkhDyndnzkPOR/atWt3QddX5IsvvtD69ev19ttv6/7777em9+zZU48++ugFyzVSU1P11VdfafHixda0rl27SjqdP5z5eaxZs0Y333yzVq9erdWrV6tZs2ZO8+rVq6dWrVpJOv1v3wslKSlJN9xwg8vVpXFxcee0H6uyn6+k346tW7fK19dXjz76qNP06jomS8pRzofo6GhFRETo9ddf18yZM8/7+qpUdVdW4P769OljPDw8Sh2hsHv3buPh4WFiY2ONMcakpKQYSWbVqlUusW+99ZaRZL7++mtr2qZNm0zfvn1N3bp1jY+Pj7n66qvNu+++6/S+omryp59+au6//35Tr149I8nk5uaaH374wdx3333myiuvNL6+viYkJMTExsZaldciVXHFRmnV7H/+859Gkhk3bpw17aWXXnIZofDZZ5+Z6OhoExAQYGrWrGlCQ0NN//79zfHjx632FX8VVbaLlrdlyxZz2223mTp16hiHw1HquopGsSxdutS0bt3a+Pj4mLCwMPPGG2+UuG3F90HRaMHVq1cbY4yJjo4usX1FVMIohW+//db069fP1KlTx/j4+Ji2bduauXPnlriexYsXm2effdY0aNDA+Pv7m27dupWrmpyXl2cCAwPNk08+6TJPktMoiCKPPvqo8fDwMPn5+U7TV65caW688Ubj7+9vfH19TadOnZyO48GDB7ts/5lV9/fff9907NjR+Pr6mssuu8x0797drF+/3mkdZX2OhYWF5s033zRt27Y1NWvWNHXq1DG33Xab+d///nfW/dCyZUsTGRl51jhjyn9slOc7U9pxcbbjuaTjLjo62rRs2dJs3LjRXH/99cbX19eEhYWZpKQkU1BQ4NS2rVu3mh49ehhfX19Tr149M2LECPPRRx85HbNF3n33XWOz2aplVBBQHpxjLt5zzLn+VpWl6DN57bXXXNo7f/5888QTT5iQkBBjs9nM9u3bTVZWlnn44YdN8+bNjZ+fn6lfv77p2rWr+eKLL1yWXXx/FW3H559/bh566CETGBhoAgICzK233mp+/fVXp/dGR0c7ndvObOfrr79uGjdubPz8/EzHjh1LHK07c+ZMEx4ebry9vU3z5s3NokWLzODBg0sdBVukaMTdtGnTyrX/cnJyzOjRo03jxo2Nl5eXCQkJMY899pg5duyY034o67xdkpEjRxqHw+HyWbZp08ZERES4THv22WfNM888Y6699lqneU2aNDEdOnSw/i7+PWrUqJFL24r2UUWP29mzZ5s2bdoYHx8fU7duXXPLLbeY7777zimm+Oda5MzP5my/EyV55JFHTI0aNZz2e0lKyqHO/G4V5WzTpk0zzZo1M15eXtaxkJCQYK677jpTt25d4+/vb9q1a2f+8Y9/mMLCwnLtz+L5TFn5XEm/d8YYs2jRItOxY0fj5+dn/Pz8TNu2bc0//vEPa/6KFStMv379zOWXX258fHxM06ZNzbBhw8zBgwetmKJlF3+d+TtY/DM6dOiQefjhh01ISIjx8vIyYWFh5tlnn3UZvV20/+bPn2+aNWtmfH19TZs2bcyHH37osi379+83NpvNzJ49u8zPDH8e5CHkIWcqT//M8ePHrXNw0bmnffv2ZvHixcaYs//mN2rUyOncUpH9VFhYaF555RXTsGFD4+PjY9q3b29WrFhR6nnuTP/617+MJJerLEuzf/9+M2zYMHP55ZcbLy8v07hxY5OQkGBOnjzptA8rct40xpi+ffu65A0FBQWmbt26pmfPni7TZs6caQYOHGjuuOMOa15eXp7x9fU1t99+uzWteL5VVh5UkdywJH5+fubOO+88a1x52lDZfr6i46b4q+i7Wvy3o6TYotyg+DFpjDHZ2dnmiSeeMGFhYcbb29vUr1/f9O7d2+nKmarOUYp8+eWX5sYbbzSXXXaZ8fX1NVFRUeajjz5yiqnoZzhhwgTj5+dnjhw5ctbP7WLCMzZwTgoKCrR69Wp16NCh1FESoaGhat++vT7//HMVFBQoNjZWQUFBmjNnjkvs3Llzdc0116hNmzaSpNWrV6tz5846fPiwpk+frvfff19XX3217rzzzhLvMffAAw/Iy8tLCxYs0L///W95eXlp3759CgwM1KuvvqrU1FS9+eab8vT0VGRkpHbs2FGl+6M0N910kzw8PPTFF1+UGvPzzz+rT58+8vb21ttvv63U1FS9+uqr8vPzU35+vho0aGCNDhwyZIjS0tKUlpamF154wWk5/fv315VXXql//etfmj59epntysjIUHx8vB5//HGlpKSoU6dOeuyxx/S3v/2twtv41ltvqXPnznI4HFbbynq+yo4dO9SpUydt27ZNf//737V06VK1aNFC9913X4lXEDz77LP65Zdf9I9//EMzZ87UDz/8oL59+6qgoKDMdm3YsEGHDh2yRjgUZ4zRqVOndOrUKR0+fFjvv/++5s2bp4EDB8rLy8uKW7hwoWJiYlS7dm3NmzdP//znPxUQEKCePXvqs88+kyS98MILevPNNyWdvk9kWlqa3nrrLUmn78l68803q3bt2nrnnXc0e/ZsZWdnq0uXLlq3bp1Lu0r6HIcPH674+Hh1795dy5Yt01tvvaVt27apU6dOOnDgQJn7ISoqShs2bNCoUaO0YcMGnTx5ssz4qjo2Sjsuyns8F5eZmam7775b99xzjz744AP17t1bY8eO1cKFC62Y/fv3Kzo6Wjt27NC0adM0f/58HT161GXURZEuXbrIGKOPP/64QtsGXCw4x7i6UOeY0pTnt+pcjB07Vrt379b06dP14YcfKigoSL///rsk6aWXXtLy5cs1Z84cNWnSRF26dCn3fZ0ffPBBeXl5afHixZo4caLWrFmje+65p1zvffPNN7Vy5UpNmTJFixYt0vHjx3XTTTcpJyfHipk5c6aGDRumNm3aaOnSpXr++ec1bty4crWvefPmqlOnjsaNG6eZM2eWeT/xP/74Q9HR0Zo3b55GjRqlTz75RE8//bTmzp2rfv36yRgjSUpLS5Ovr69uuukm65gqOm+XZvny5brhhhtUo4bzP6O6du2qHTt2aP/+/ZKkQ4cO6dtvv1V0dLSio6P11Vdf6ciRI5JOP3Pip59+KjU3kaSUlBQ1adJE7dq1s9pW/Dki5Tluk5KSNGTIELVs2VJLly7VG2+8oW+++UZRUVH64YcfytzW4ipz7o6KilJhYaH69++vTz/91NoHxb3wwgu6/fbbJcklXyiybNkyTZs2TS+++KI+/fRT/eUvf5F0+vdt+PDh+uc//6mlS5eqf//+GjlypP76179WaH+e2ZbS8rmSvPjii7r77rsVEhKiuXPnKiUlRYMHD7buiy6dfi5LVFSUpk2bphUrVujFF1/Uhg0bdP3111s52YMPPqiRI0dKkpYuXWq185prrilxvSdOnFDXrl01f/58PfHEE1q+fLnuueceTZw4scSrlJcvX67k5GSNHz9e7733ngICAnTrrbfqp59+copzOBxq1qyZli9fXuo2A2ciD3F1qeYh5e2feeKJJzRt2jSNGjVKqampWrBgge644w4dOnRIUvl+80tSnv303HPP6bnnnlOvXr30/vvv66GHHtKDDz6onTt3nnX7OnToIC8vLz322GNatGiRdU4vSWZmpq677jp9+umnevHFF/XJJ59oyJAhSkpK0tChQyVV7ryZn5+vVatWueQIRVd5rlu3znrORkZGhrKzs61c48xngKSnpys3N7fMXKM8eVBlc8OoqCi99957SkhI0Ndff13qsVyeNlS2n++aa66x+h2ff/55a/kPPvhgqW256aab5Ovra8X26dOnxNijR4/q+uuv14wZM3T//ffrww8/1PTp03XVVVc5HTdVnaNI0tq1a3XjjTcqJydHs2fP1jvvvCN/f3/17dtX7777rkt8eT/DLl266Pjx4xV+Hky1q+bCCtxcZmamkWQGDhxYZtydd95pJJkDBw4YY4x54oknjK+vrzl8+LAV89133xlJTs/jaNasmWnXrp1V8S4SGxtrGjRoYI04KKpE3nvvvWdt86lTp0x+fr4JDw83jz/+uDX9fF6xYYwxwcHBpnnz5tbfxavDRfdnzsjIKHUZZd2fsWh5Jd0Tt7RRLDabzWV9PXr0MLVr17aeC1HeUSzGlH3f0eLtHjhwoPHx8TG7d+92iuvdu7epVauWdWwUreemm25yiisaGXS2e7dOmDDBSDKZmZkltqmkV+/evZ1GFh4/ftwEBASYvn37Or2/oKDAtG3b1lx33XUu++XM+14XFBSYkJAQ07p1a6dRMkePHjVBQUGmU6dO1rTSPse0tDQjybz++utO0/fs2WN8fX3NU089VeZ++O2338z1119vbaOXl5fp1KmTSUpKMkePHnWKLe+xUd7vTGWesVHa6CNJZsOGDU6xLVq0cBq58uSTTxqbzeZy/9eePXu6HLNFLr/88nKNKAGqA+eY0y7Gc8y5/FadTVlXbNxwww1nff+pU6fMyZMnTbdu3cytt97qNK/4/irajhEjRjjFTZw40Ugy+/fvd9q+kq7YaN26tTl16pQ1fePGjUb6v+dOFBQUGIfD4XL14C+//GK8vLzOesWGMcYsX77cGq0nyQQGBpo77rjDek5FkaSkJFOjRg2X70zR9+Djjz+2plXkvs4HDhwwksyrr77qMm/ZsmXWaFJjjHnvvfeMp6enOXr0qDly5Ijx8PCwRtLNmzfPpR0lfY/O9oyNsx232dnZxtfX1yVu9+7dxsfHxwwaNMiaVp4rNoyp+L3CCwsLzfDhw02NGjWMJGOz2Uzz5s3N448/7vK9L+t+65KM3W43v//+e5nrKygoMCdPnjTjx483gYGBTiMiS9ufJeUzpT3HpPjn9NNPPxkPDw9z9913l9muMxUWFpqTJ0+aX375xUgy77//vjWvrGdsFP+Mpk+fbiSZf/7zn05xRbnvihUrrGmSTHBwsNMozMzMTFOjRg2TlJTksq67777bBAcHl3ubcGkjDzmNPKT8/TOtWrUyt9xyS5nLL+s3v7QrNs62n37//Xfj4+Pj8u+6on9Ln+2KDWNOX+V42WWXWblGgwYNzL333utyBezw4cPNZZddZn755Ren6UXPwij6t2hFz5sbNmwwksySJUtc5hU9/6Horg+vv/66adCggTHm//rTtm7daowxZty4cUaS0xWaJV0he7ZnbJQnNyzJjz/+aFq1amXtR19fX9OtWzeTnJzscmeMs7XhXPr5ynrGRkm/HYMHDzZ+fn4uscWPyaLnlxR/vlBZqipH6dixowkKCnLqxzl16pRp1aqVueKKK6zlVvQzzM/PNzabzTz99NPl3qaLAVds4IIw/39kXNF98B544AHl5uY6VRPnzJkjHx8fDRo0SJL0448/6vvvv9fdd98tSdao+lOnTummm27S/v37Xa64uO2221zWferUKSUmJqpFixby9vaWp6envL299cMPP2j79u3nZXtLUrQPSnP11VfL29tbw4YN07x581xGT5VXSfugNC1btlTbtm2dpg0aNEhHjhzRV199Van1l9fnn3+ubt26KTQ01Gn6fffdpz/++MNlBEy/fv2c/i66qufM0XAl2bdvn2w2m+rVq1fi/AEDBmjTpk3atGmTvvjiC/3973/X5s2b1atXL+Xl5UmS1q9fr99//12DBw92Og4LCwvVq1cvbdq0ScePHy+1DTt27NC+ffsUFxfnNMLzsssu02233ab09HT98ccfTu8p/jl+9NFHstlsuueee5za4HA41LZt27NW1QMDA/Xll19q06ZNevXVV3XzzTdr586dGjt2rFq3bq3ffvvNKb46j42yOBwOXXfddU7T2rRp43QcrF27Vq1atXK5F/Vdd91V6nKDgoL066+/Vm1jgQuIc4yzC3WOKU15fqvORWmfw/Tp03XNNdeoZs2a8vT0lJeXlz777LNy5zvnsh/69OkjDw+PUt+7Y8cOZWZmasCAAU7va9iwYbmfwXbTTTdp9+7dSklJ0ZgxY9SyZUstW7ZM/fr1c7oq76OPPlKrVq109dVXO50ze/bsaT0LozL27dsn6fQ5o7jo6GjVqFHDWvaaNWvUoUMHXXbZZfL399c111yj1atXW/M8PT11/fXXV6odRc72eaWlpSk3N1f33XefU1xoaKhuvPFG64rT88lms2n69On66aef9NZbb+n+++/XyZMnNXnyZLVs2dJpdOnZ3Hjjjapbt67L9M8//1zdu3eX3W6Xh4eHvLy89OKLL+rQoUPKysqqys1xsXLlShUUFOiRRx4pMy4rK0sPPfSQQkNDre9mo0aNJKnS/x75/PPP5efnZ416LlL0eRf/fLt27Sp/f3/r7+DgYAUFBZX4/Q4KClJWVpY1Khg4G/IQZ5diHlKR/pnrrrtOn3zyiZ555hmtWbNGubm5lV7vmc62n9LT05WXl+eSa3Ts2FGNGzcu1zoeeOAB7d27V4sXL9aoUaMUGhqqhQsXKjo6Wq+99poV99FHH6lr164KCQlx2he9e/eWpAqd385UVq5x5nM2iv5b9Byo5s2bKygoyCnXCA4OVvPmzSvVjiKVPTabNm2qr7/+WmvXrtW4cePUvXt3bdq0SY8++qiioqJ04sSJcrfhYuzn++STT3TVVVepe/fuZcZVdY5y/PhxbdiwQbfffrsuu+wya7qHh4fi4uK0d+9el37S8n6GXl5eqlOnjtv1i1DYwDmpV6+eatWqpV27dpUZ9/PPP6tWrVoKCAiQdDrJuPbaa63LwgoKCrRw4ULdfPPNVkzRrXXGjBkjLy8vp9eIESMkyaUztqRLF5944gm98MILuuWWW/Thhx9qw4YN2rRpk9q2bVtlJ9izOX78uA4dOqSQkJBSY5o2bapVq1YpKChIjzzyiJo2baqmTZvqjTfeqNC6znb55pkcDkep04ouEz1fDh06VGJbi/ZR8fUHBgY6/e3j4yNJZ/0Mc3Nz5eXl5dTZcqb69eurQ4cO6tChg/7yl79o5MiR+vvf/65169ZZl9MWHYu33367y7E4YcIEGWOsW4CUtq1SyZ9NSEiICgsLlZ2d7TS9eOyBAwdkjFFwcLBLG9LT012+C6Xp0KGDnn76af3rX//Svn379Pjjj+vnn392uSS6Oo+NshQ/DqTTx8KZx8GhQ4esBxeeqaRpRWrWrHnBfg+AqsY5xtWFOseUpjy/VeeipG2bNGmSHn74YUVGRuq9995Tenq6Nm3apF69epV7veeyH8723qJ9XtHf5+J8fX11yy236LXXXtPatWv1448/qkWLFnrzzTe1bds2SafPmd98843L+dLf31/GmHKfM4sr2paaNWu6zKtTp46uvvpqq0Nh9erVTg+djo6Otjoiim7jemYnc2WUd5+X9l24kOfzRo0a6eGHH9bs2bP1ww8/6N1339WJEyf05JNPlnsZJW3Hxo0bFRMTI+n0g8r/85//aNOmTXruueckVf47XF4HDx6UpDIfXFxYWKiYmBgtXbpUTz31lD777DNt3LhR6enp59TGQ4cOyeFwuDxANSgoSJ6enmf9nZNK/12qWbOm9YB24GzIQ1xdinlIRfpn/v73v+vpp5/WsmXL1LVrVwUEBOiWW26p8C0Qi7tQuYbdbtddd92lN954Qxs2bNA333yj4OBgPffcczp8+LCk0/vjww8/dNkXLVu2lOTaV1VeZeUarVu3Vr169bR69WoVFhbqyy+/dMo1brjhBq1Zs0Z5eXlKS0sr8zZU5XUux2bR7bNefPFFffDBB9q3b5/uvPNObdmyRW+//Xa523Ax9vMdPHiwzHO/dH5ylOzsbBljztvvizv2i3hWdwPg3jw8PNS1a1elpqZq7969JX6x9+7dqy1btqh3795Oncv333+/RowYoe3bt+unn37S/v37df/991vzi0bYjx07tsT7xEpSRESE09/FE3vp9LMR7r33XiUmJjpN/+2331SnTp1yb+u5WL58uQoKCtSlS5cy4/7yl7/oL3/5iwoKCrR582ZNnTpV8fHxCg4O1sCBA8u1rpL2QWkyMzNLnVb041d0Qi26eqFIZU/URQIDA0u8Z2XRCIXSrrCoqHr16ik/P1/Hjx+Xn59fud5TVMH++uuvndoydepUdezYscT3lJUoFe3L0ra3Ro0aLiMQi3+O9erVk81m05dffmmdiM5U0rSz8fLy0ksvvaTJkydr69atTvPKc2xcrAIDA0t85khJ21Tk999/L/coHuBiwznG1YU6x1SX0vKdLl26aNq0aU7Tjx49eqGaVaaiz7yiv89n07BhQw0bNkzx8fHatm2bWrZsqXr16snX17fUfzRX9vMvel9pgxm6du2q119/Xd988422bdvmNGggOjpakyZN0jfffKOff/65zKsIq8rZ8o8z90PNmjWdnodS5Fy/i6UZMGCAkpKSXPKPspR03C9ZskReXl766KOPnDqBli1bVhXNPKv69etLOv3vneIjs4ts3bpVX3/9tebOnavBgwdb03/88cdzWndgYKA2bNggY4zTvim60uJcfud+//13+fj4OI0GBUpDHuLqUsxDKtI/4+fnp3HjxmncuHE6cOCAdfVG37599f3335+3Np4t16jsv/datmypgQMHasqUKdq5c6euu+461atXT23atNErr7xS4nvKKvSVpaxcw2azKTo6Wqmpqdq4caMOHz7sMogiISFBaWlp1nOYLiZ+fn4aO3as3n333XM+/1d3P1/9+vW1d+/eMmPOR45St25d1ahR47z9vmRnZ7vd7xNXbOCcjR07VsYYjRgxwuWBQAUFBXr44YdljNHYsWOd5t11112qWbOm5s6dq7lz5+ryyy+3qpnS6ZNieHi4vv76a2tEffFXeUa62Ww2l07f5cuXX7DLq3bv3q0xY8bIbrdr+PDh5XqPh4eHIiMjrQcXFl0qe64jN4rbtm2b1XlfZPHixdYtEyRZJ/9vvvnGKe6DDz5wWV5FRoF069ZNn3/+ufXjW2T+/PmqVatWqQWEimrWrJmk0w9tLK+MjAxJ/3f5Z+fOnVWnTh199913pR6L3t7epS4vIiJCl19+uRYvXux0mfbx48f13nvvKSoqSrVq1SqzTbGxsTLG6Ndffy1x/a1bty7z/aU9+KzoMs3iiVd5jo3yKu24qOrjuUh0dLS2bt2q7777zmn6kiVLSow/deqU9uzZ43LrKsAdcI4p2YU6x1xMSsp3vvnmmzIfbnohRUREyOFw6J///KfT9N27d2v9+vVnff/Ro0d17NixEucVP5fFxsbqf//7nwIDA0s8Z57ZsVGR46pRo0by9fUtNaco6kAYN26catSo4XSrqaL/HzdunFNsWc51dG1UVJR8fX1dHha7d+9e6zYpRRo3bqydO3c6de4dOnTI5bOp6O9EafnHsWPHtGfPHqf8ozK/QTabTZ6enk6Dp3Jzc7VgwQKX2Kq8aqpITEyMPDw8XAqKxdtYtP4zzZgxo8Q2SuXbB926ddOxY8dcOkjmz59vza+sn376ibwI5UIeUrJLMQ+pbP9McHCw7rvvPt11113asWOHdQvm8/FvwcjISPn4+Lg8QDk9Pb1ct+E6dOiQ8vPzS5xXVJA5M9fYunWrmjZtWuK+KIqr6HYW3TqqrFzj+PHjeu211xQUFOR0q6no6GgdOnRIU6dOtWLP5nycG6WK9T9Upg3l7ec7X30OvXv31s6dO/X555+X2caqzlH8/PwUGRmppUuXOsUXFhZq4cKFuuKKK3TVVVdVcGtO27dvn06cOOF253+u2MA569y5s6ZMmaL4+Hhdf/31evTRR9WwYUPt3r1bb775pjZs2KApU6aoU6dOTu+rU6eObr31Vs2dO1eHDx/WmDFjnJ4/IJ1O+Hv37q2ePXvqvvvu0+WXX67ff/9d27dv11dffaV//etfZ21fbGys5s6dq2bNmqlNmzbasmWLXnvttbNeNlYZW7dute6tmJWVpS+//FJz5syRh4eHUlJSrFFdJZk+fbo+//xz9enTRw0bNtSJEyeskYZF9+3z9/dXo0aN9P7776tbt24KCAhQvXr1Kj3yICQkRP369VNCQoIaNGighQsXauXKlZowYYLV0X7ttdcqIiJCY8aM0alTp1S3bl2lpKRo3bp1Lstr3bq1li5dqmnTpql9+/aqUaOGOnToUOK6X3rpJeu+lC+++KICAgK0aNEiLV++XBMnTpTdbq/UNhVXNHIoPT3duhLjTAcOHLBuBXDixAllZGTo5ZdfVp06dawriC677DJNnTpVgwcP1u+//67bb79dQUFBOnjwoL7++msdPHiwzH/Q1qhRQxMnTtTdd9+t2NhYDR8+XHl5eXrttdd0+PBhvfrqq2fdjs6dO2vYsGG6//77tXnzZt1www3y8/PT/v37tW7dOrVu3VoPP/xwqe/v2bOnrrjiCvXt21fNmjVTYWGhMjIy9Prrr+uyyy7TY4895hRfnmOjvEo7Lqr6eC4SHx+vt99+W71799b48eMVHBysxYsXW8lo8d+Zb775Rn/88cdFN6IFKI5zzMV3jrmYxMbG6q9//ateeuklRUdHa8eOHRo/frzCwsIuivvk16hRQ+PGjdPw4cN1++2364EHHtDhw4c1btw4NWjQwOW3ubgdO3aoZ8+eGjhwoKKjo9WgQQNlZ2dr+fLlmjlzprp06WLlmvHx8Xrvvfd0ww036PHHH1ebNm1UWFio3bt3a8WKFRo9erQiIyMlnT6u1qxZow8//FANGjSQv7+/yxXBRby9vRUVFWXlDcXdcMMN1vexeAdPnTp11LZtW6WkpMjLy6tczxVp3bq1lixZonfffVdNmjRRzZo1zzqQ4Ux16tTRCy+8oGeffVb33nuv7rrrLh06dEjjxo1TzZo19dJLL1mxcXFxmjFjhu655x4NHTpUhw4d0sSJE1W7dm2nZVb0d+KVV17Rf/7zH9155526+uqr5evrq127dik5OVmHDh1yul950bZNmDDButK7TZs2ZQ4e6dOnjyZNmqRBgwZp2LBhOnTokP72t7+VeCXrue7PkjRu3FjPPvus/vrXvyo3N1d33XWX7Ha7vvvuO/32228aN26cmjVrpqZNm+qZZ56RMUYBAQH68MMPtXLlyhLbKElvvPGGBg8eLC8vL0VERJTYWXjvvffqzTff1ODBg/Xzzz+rdevWWrdunRITE3XTTTed9b7fpSksLNTGjRs1ZMiQSr0fly7yEPKQ8vbPREZGKjY2Vm3atFHdunW1fft2LViwwGlAX2V+888mICBATzzxhJKSklS3bl3deuut2rt3b7lzjdWrV+uxxx7T3XffrU6dOikwMFBZWVl65513lJqaqnvvvdfqRxo/frxWrlypTp06adSoUYqIiNCJEyf0888/6+OPP9b06dN1xRVXVPi4vuKKK9SkSROlp6dr1KhRLvOL/s2akpLi8oylVq1aKTAwUCkpKbr88ssVHh5+1n1WkTyoIlq2bKlu3bqpd+/eatq0qU6cOKENGzbo9ddfV3BwsNM5pjJtKG8/X9OmTeXr66tFixapefPmuuyyyxQSElLpK2qKxMfH691339XNN9+sZ555Rtddd51yc3O1du1axcbGqmvXructR0lKSlKPHj3UtWtXjRkzRt7e3nrrrbe0detWvfPOOxW6su1MRfmt2/WLVMMDy3GJSktLM7fffrsJDg42np6eJigoyPTv39+sX7++1PesWLHCSDKSzM6dO0uM+frrr82AAQNMUFCQ8fLyMg6Hw9x4441m+vTpVsycOXOMJLNp0yaX92dnZ5shQ4aYoKAgU6tWLXP99debL7/80kRHR5vo6GgrbteuXUaSmTNnjstyd+3aVea2F8UVvby9vU1QUJCJjo42iYmJJisry+U9L730kjnzK5iWlmZuvfVW06hRI+Pj42MCAwNNdHS0+eCDD5zet2rVKtOuXTvj4+NjJJnBgwc7Le/gwYNnXZcxxjRq1Mj06dPH/Pvf/zYtW7Y03t7epnHjxmbSpEku79+5c6eJiYkxtWvXNvXr1zcjR440y5cvN5LM6tWrrbjff//d3H777aZOnTrGZrM5rVOSeemll5yW++2335q+ffsau91uvL29Tdu2bZ32vzHGrF692kgy//rXv5yml/R5leYvf/mLuemmm1ymn/mZSTJeXl6mSZMm5v777zc//vijS/zatWtNnz59TEBAgPHy8jKXX3656dOnj1PbSmuvMcYsW7bMREZGmpo1axo/Pz/TrVs385///McppqzP0Rhj3n77bRMZGWn8/PyMr6+vadq0qbn33nvN5s2by9wH7777rhk0aJAJDw83l112mfHy8jINGzY0cXFx5rvvvnOKLe+xUd7vTFnHRWnHc0nLiY6ONi1btnTZtsGDB5tGjRo5Tdu6davp3r27qVmzpgkICDBDhgwx8+bNM5LM119/7RT7wgsvmHr16pkTJ06UuQ+B6sI55rSL8Rxzrr9VZSlqw2uvvXbW9hpjTF5enhkzZoy5/PLLTc2aNc0111xjli1bVuJ6i++v0vKoovWd+TmUlj+d2c7S1mOMMTNnzjRXXnml8fb2NldddZV5++23zc0332zatWtX5v7Izs42L7/8srnxxhvN5Zdfbry9vY2fn5+5+uqrzcsvv2z++OMPp/hjx46Z559/3kRERBhvb29jt9tN69atzeOPP24yMzOtuIyMDNO5c2dTq1YtI8lp20oye/Zs4+HhYfbt21fi/Ouuu85IMmPGjHGZFx8fbySZzp07u8wr6Xv0888/m5iYGOPv728kWZ9jRY/bf/zjH6ZNmzbWfrj55pvNtm3bXNowb94807x5c1OzZk3TokUL8+6775Z4/JT2O1GS9PR088gjj5i2bduagIAA4+HhYerXr2969eplPv74Y6fYvLw88+CDD5r69etb3/Gi75Yk88gjj5S4jrfffttEREQYHx8f06RJE5OUlGRmz57t8t0sbX+WtN9K28clfU7GGDN//nxz7bXXmpo1a5rLLrvMtGvXzml53333nenRo4fx9/c3devWNXfccYfZvXt3id+RsWPHmpCQEFOjRg2n71/x754xxhw6dMg89NBDpkGDBsbT09M0atTIjB071iWnKW3/NWrUyOXz++yzz4wks2XLFpd4/DmRh5xGHnJaefpnnnnmGdOhQwdTt25d67f58ccfN7/99psVU9ZvfvHfporsp8LCQvPyyy+bK664wnh7e5s2bdqYjz76yLRt29bceuutZW7znj17zPPPP286d+5sHA6H8fT0NP7+/iYyMtJMnTrVnDp1yin+4MGDZtSoUSYsLMx4eXmZgIAA0759e/Pcc8+ZY8eOWXEVOW8ac/rfp3Xr1i3136cOh8NIMsnJyS7zbrnlFiPJ3H333S7zSjoGSsuDKpIblmTGjBmmf//+pkmTJqZWrVrG29vbNG3a1Dz00ENmz54959QGY8rfz2eMMe+8845p1qyZ8fLycvqulvTbMXjwYOPn5+eyvpLOl9nZ2eaxxx4zDRs2NF5eXiYoKMj06dPHfP/991bM+chRjDHmyy+/NDfeeKPVL9SxY0fz4YcfOsVU9DOMi4szrVu3dtn2i53NmDPuiwIAl6D33ntPd955p3755Rddfvnl1d2ci17jxo3VqlUrffTRR9XdlCo1bNgwvfPOOzp06JA1EqigoEBXXnmlBg0aVOr9UQEA58/hw4d11VVX6ZZbbtHMmTOruzlndeLECTVs2FCjR4/W008/Xd3NAapcXFycfvrpJ/3nP/+p7qYAQJXYtWuXmjVrppdeeknPPvtsdTfnrPbt26ewsDDNnz9fd955Z3U3B38CR44cUUhIiCZPnqyhQ4dWd3MqhMIGgEueMUadOnVS+/btlZycXN3NuehdCoWN8ePHKyQkRE2aNNGxY8f00Ucf6R//+Ieef/55jR8/3oqbN2+exowZox9++OGCPGQMAP7MMjMz9corr6hr164KDAzUL7/8osmTJ+v777/X5s2b1bJly+puYrlMmzZNCQkJ+umnn+Tn51fdzQGqzP/+9z81b95cn3/+udMzYgDAXXz99dd655131KlTJ9WuXVs7duzQxIkTdeTIEW3dulXBwcHV3cRyefrpp/XJJ58oIyPjrLfQAs7VuHHj9O677+qbb76Rp6d7PbXCvVoLAJVgs9k0a9YsffDBByosLCQx+BPw8vLSa6+9pr179+rUqVMKDw/XpEmTXJ4lUlhYqEWLFlHUAIALwMfHRz///LNGjBih33//3XqA6vTp092mqCGdvgLw8OHD+umnn875GQ3AxWT37t1KTk6mqAHAbfn5+Wnz5s2aPXu2Dh8+LLvdri5duuiVV15xm6KGJD3//POqVauWfv31V4WGhlZ3c3CJq127tubOnet2RQ2JKzYAAAAAAAAAAIAbYdgyAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3Ib7PRWkmhQWFmrfvn3y9/eXzWar7uYAAHBBGGN09OhRhYSEqEYNxkNUFPkDAODPihyi8sgfAAB/VhXJHyhslNO+ffsUGhpa3c0AAKBa7NmzR1dccUV1N8PtkD8AAP7syCEqjvwBAPBnV578gcJGOfn7+0s6vVNr165dza0BAODCOHLkiEJDQ63zICqG/AEA8GdFDlF55A8AgD+riuQPFDbKqejyz9q1a5NYAAD+dLgNQuWQPwAA/uzIISqO/AEA8GdXnvyBG10CAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVRrYePUqVN6/vnnFRYWJl9fXzVp0kTjx49XYWGhFWOMUUJCgkJCQuTr66suXbpo27ZtTsvJy8vTyJEjVa9ePfn5+alfv37au3evU0x2drbi4uJkt9tlt9sVFxenw4cPX4jNBAAAAAAA1eyLL75Q3759FRISIpvNpmXLlrnEbN++Xf369ZPdbpe/v786duyo3bt3W/PpfwAA4OJQrYWNCRMmaPr06UpOTtb27ds1ceJEvfbaa5o6daoVM3HiRE2aNEnJycnatGmTHA6HevTooaNHj1ox8fHxSklJ0ZIlS7Ru3TodO3ZMsbGxKigosGIGDRqkjIwMpaamKjU1VRkZGYqLi7ug2wsAAAAAAKrH8ePH1bZtWyUnJ5c4/3//+5+uv/56NWvWTGvWrNHXX3+tF154QTVr1rRi6H8AAODiYDPGmOpaeWxsrIKDgzV79mxr2m233aZatWppwYIFMsYoJCRE8fHxevrppyWdHh0RHBysCRMmaPjw4crJyVH9+vW1YMEC3XnnnZKkffv2KTQ0VB9//LF69uyp7du3q0WLFkpPT1dkZKQkKT09XVFRUfr+++8VERFx1rYeOXJEdrtdOTk5ql279nnYGwAAXHw4/50b9h8A4M/qYj8H2mw2paSk6JZbbrGmDRw4UF5eXlqwYEGJ76H/AQCA86si58BqvWLj+uuv12effaadO3dKkr7++mutW7dON910kyRp165dyszMVExMjPUeHx8fRUdHa/369ZKkLVu26OTJk04xISEhatWqlRWTlpYmu91uJRWS1LFjR9ntdiumuLy8PB05csTpBQAAAAAALj2FhYVavny5rrrqKvXs2VNBQUGKjIx0ul0V/Q8AAFw8qrWw8fTTT+uuu+5Ss2bN5OXlpXbt2ik+Pl533XWXJCkzM1OSFBwc7PS+4OBga15mZqa8vb1Vt27dMmOCgoJc1h8UFGTFFJeUlGTdD9Nutys0NPTcNhYAAAAAAFyUsrKydOzYMb366qvq1auXVqxYoVtvvVX9+/fX2rVrJdH/AADAxaRaCxvvvvuuFi5cqMWLF+urr77SvHnz9Le//U3z5s1zirPZbE5/G2NcphVXPKak+LKWM3bsWOXk5FivPXv2lHezAAAAAACAGyksLJQk3XzzzXr88cd19dVX65lnnlFsbKymT59e5nvpfwAA4MLzrM6VP/nkk3rmmWc0cOBASVLr1q31yy+/KCkpSYMHD5bD4ZB0esRDgwYNrPdlZWVZV3E4HA7l5+crOzvbadREVlaWOnXqZMUcOHDAZf0HDx50uRqkiI+Pj3x8fKpmQwEAAAAAwEWrXr168vT0VIsWLZymN2/eXOvWrZNE/wMAABeTar1i448//lCNGs5N8PDwsEZKhIWFyeFwaOXKldb8/Px8rV271koa2rdvLy8vL6eY/fv3a+vWrVZMVFSUcnJytHHjRitmw4YNysnJsWIAAAAAAMCfk7e3t6699lrt2LHDafrOnTvVqFEjSfQ/AABwManWKzb69u2rV155RQ0bNlTLli313//+V5MmTdIDDzwg6fTlm/Hx8UpMTFR4eLjCw8OVmJioWrVqadCgQZIku92uIUOGaPTo0QoMDFRAQIDGjBmj1q1bq3v37pJOj7Do1auXhg4dqhkzZkiShg0bptjYWEVERFTPxgMAAAAAgAvm2LFj+vHHH62/d+3apYyMDAUEBKhhw4Z68skndeedd+qGG25Q165dlZqaqg8//FBr1qyRRP8DAAAXk2otbEydOlUvvPCCRowYoaysLIWEhGj48OF68cUXrZinnnpKubm5GjFihLKzsxUZGakVK1bI39/fipk8ebI8PT01YMAA5ebmqlu3bpo7d648PDysmEWLFmnUqFGKiYmRJPXr10/JyckXbmMBAAAAAEC12bx5s7p27Wr9/cQTT0iSBg8erLlz5+rWW2/V9OnTlZSUpFGjRikiIkLvvfeerr/+eus99D8AAHBxsBljTHU3wh0cOXJEdrtdOTk5ql27dpUsc+mO/VWyHFw8+kc0OHsQALiR83H++zM5X/uPHOLSQv4A4FJEDlF55A8oD/IHAJeiipwDq/UZGwAAAAAAAAAAABVBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAA3M6vv/6qe+65R4GBgapVq5auvvpqbdmyxZpvjFFCQoJCQkLk6+urLl26aNu2bU7LyMvL08iRI1WvXj35+fmpX79+2rt3r1NMdna24uLiZLfbZbfbFRcXp8OHD1+ITQQAAAAAAKWgsAEAANxKdna2OnfuLC8vL33yySf67rvv9Prrr6tOnTpWzMSJEzVp0iQlJydr06ZNcjgc6tGjh44ePWrFxMfHKyUlRUuWLNG6det07NgxxcbGqqCgwIoZNGiQMjIylJqaqtTUVGVkZCguLu5Cbi4AAAAAACjGs7obAAAAUBETJkxQaGio5syZY01r3Lix9f/GGE2ZMkXPPfec+vfvL0maN2+egoODtXjxYg0fPlw5OTmaPXu2FixYoO7du0uSFi5cqNDQUK1atUo9e/bU9u3blZqaqvT0dEVGRkqSZs2apaioKO3YsUMREREXbqMBAAAAAICFKzYAAIBb+eCDD9ShQwfdcccdCgoKUrt27TRr1ixr/q5du5SZmamYmBhrmo+Pj6Kjo7V+/XpJ0pYtW3Ty5EmnmJCQELVq1cqKSUtLk91ut4oaktSxY0fZ7XYrpri8vDwdOXLE6QUAAAAAAKoWhQ0AAOBWfvrpJ02bNk3h4eH69NNP9dBDD2nUqFGaP3++JCkzM1OSFBwc7PS+4OBga15mZqa8vb1Vt27dMmOCgoJc1h8UFGTFFJeUlGQ9j8Nutys0NPTcNhYAAAAAALigsAEAANxKYWGhrrnmGiUmJqpdu3YaPny4hg4dqmnTpjnF2Ww2p7+NMS7TiiseU1J8WcsZO3ascnJyrNeePXvKu1kAAAAAAKCcKGwAAAC30qBBA7Vo0cJpWvPmzbV7925JksPhkCSXqyqysrKsqzgcDofy8/OVnZ1dZsyBAwdc1n/w4EGXq0GK+Pj4qHbt2k4vAAAAAABQtShsAAAAt9K5c2ft2LHDadrOnTvVqFEjSVJYWJgcDodWrlxpzc/Pz9fatWvVqVMnSVL79u3l5eXlFLN//35t3brViomKilJOTo42btxoxWzYsEE5OTlWDAAAAAAAuPA8q7sBAAAAFfH444+rU6dOSkxM1IABA7Rx40bNnDlTM2fOlHT69lHx8fFKTExUeHi4wsPDlZiYqFq1amnQoEGSJLvdriFDhmj06NEKDAxUQECAxowZo9atW6t79+6STl8F0qtXLw0dOlQzZsyQJA0bNkyxsbGKiIiono0HAAAAAAAUNgAAgHu59tprlZKSorFjx2r8+PEKCwvTlClTdPfdd1sxTz31lHJzczVixAhlZ2crMjJSK1askL+/vxUzefJkeXp6asCAAcrNzVW3bt00d+5ceXh4WDGLFi3SqFGjFBMTI0nq16+fkpOTL9zGAgAAAAAAFzZjjKnuRriDI0eOyG63Kycnp8rul710x/4qWQ4uHv0jGlR3EwCgSp2P89+fyfnaf+QQlxbyBwCXInKIyiN/QHmQPwC4FFXkHMgzNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNuo1sJG48aNZbPZXF6PPPKIJMkYo4SEBIWEhMjX11ddunTRtm3bnJaRl5enkSNHql69evLz81O/fv20d+9ep5js7GzFxcXJbrfLbrcrLi5Ohw8fvlCbCQAAAAAAqtkXX3yhvn37KiQkRDabTcuWLSs1dvjw4bLZbJoyZYrTdPogAAC4OFRrYWPTpk3av3+/9Vq5cqUk6Y477pAkTZw4UZMmTVJycrI2bdokh8OhHj166OjRo9Yy4uPjlZKSoiVLlmjdunU6duyYYmNjVVBQYMUMGjRIGRkZSk1NVWpqqjIyMhQXF3dhNxYAAAAAAFSb48ePq23btkpOTi4zbtmyZdqwYYNCQkJc5tEHAQDAxcGzOldev359p79fffVVNW3aVNHR0TLGaMqUKXruuefUv39/SdK8efMUHBysxYsXa/jw4crJydHs2bO1YMECde/eXZK0cOFChYaGatWqVerZs6e2b9+u1NRUpaenKzIyUpI0a9YsRUVFaceOHYqIiLiwGw0AAAAAAC643r17q3fv3mXG/Prrr3r00Uf16aefqk+fPk7z6IMAAODicdE8YyM/P18LFy7UAw88IJvNpl27dikzM1MxMTFWjI+Pj6Kjo7V+/XpJ0pYtW3Ty5EmnmJCQELVq1cqKSUtLk91utxIKSerYsaPsdrsVU5K8vDwdOXLE6QUAAAAAAC5NhYWFiouL05NPPqmWLVu6zD9ffRD0PwAAUHEXTWFj2bJlOnz4sO677z5JUmZmpiQpODjYKS44ONial5mZKW9vb9WtW7fMmKCgIJf1BQUFWTElSUpKsu6HabfbFRoaWultAwAAAAAAF7cJEybI09NTo0aNKnH++eqDoP8BAICKu2gKG7Nnz1bv3r1d7mFps9mc/jbGuEwrrnhMSfFnW87YsWOVk5Njvfbs2VOezQAAAAAAAG5my5YteuONNzR37tyz9jkUd659EPQ/AABQcRdFYeOXX37RqlWr9OCDD1rTHA6HJLmMaMjKyrKu4nA4HMrPz1d2dnaZMQcOHHBZ58GDB12uBjmTj4+Pateu7fQCAAAAAACXni+//FJZWVlq2LChPD095enpqV9++UWjR49W48aNJZ2/Pgj6HwAAqLiLorAxZ84cBQUFOT2YKywsTA6HQytXrrSm5efna+3aterUqZMkqX379vLy8nKK2b9/v7Zu3WrFREVFKScnRxs3brRiNmzYoJycHCsGAAAAAAD8ecXFxembb75RRkaG9QoJCdGTTz6pTz/9VBJ9EAAAXEw8q7sBhYWFmjNnjgYPHixPz/9rjs1mU3x8vBITExUeHq7w8HAlJiaqVq1aGjRokCTJbrdryJAhGj16tAIDAxUQEKAxY8aodevW6t69uySpefPm6tWrl4YOHaoZM2ZIkoYNG6bY2FhFRERc+A0GAAAAAAAX3LFjx/Tjjz9af+/atUsZGRkKCAhQw4YNFRgY6BTv5eUlh8Nh9R3QBwEAwMWj2gsbq1at0u7du/XAAw+4zHvqqaeUm5urESNGKDs7W5GRkVqxYoX8/f2tmMmTJ8vT01MDBgxQbm6uunXrprlz58rDw8OKWbRokUaNGqWYmBhJUr9+/ZScnHz+Nw4AAAAAAFwUNm/erK5du1p/P/HEE5KkwYMHa+7cueVaBn0QAABcHGzGGFPdjXAHR44ckd1uV05OTpXd73Lpjv1VshxcPPpHNKjuJgBAlTof578/k/O1/8ghLi3kDwAuReQQlUf+gPIgfwBwKarIOfCieMYGAAAAAAAAAABAeVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAOBWEhISZLPZnF4Oh8Oab4xRQkKCQkJC5Ovrqy5dumjbtm1Oy8jLy9PIkSNVr149+fn5qV+/ftq7d69TTHZ2tuLi4mS322W32xUXF6fDhw9fiE0EAAAAAABloLABAADcTsuWLbV//37r9e2331rzJk6cqEmTJik5OVmbNm2Sw+FQjx49dPToUSsmPj5eKSkpWrJkidatW6djx44pNjZWBQUFVsygQYOUkZGh1NRUpaamKiMjQ3FxcRd0OwEAAAAAgCvP6m4AAABARXl6ejpdpVHEGKMpU6boueeeU//+/SVJ8+bNU3BwsBYvXqzhw4crJydHs2fP1oIFC9S9e3dJ0sKFCxUaGqpVq1apZ8+e2r59u1JTU5Wenq7IyEhJ0qxZsxQVFaUdO3YoIiLiwm0sAAAAAABwwhUbAADA7fzwww8KCQlRWFiYBg4cqJ9++kmStGvXLmVmZiomJsaK9fHxUXR0tNavXy9J2rJli06ePOkUExISolatWlkxaWlpstvtVlFDkjp27Ci73W7FlCQvL09HjhxxegEAAAAAgKpFYQMAALiVyMhIzZ8/X59++qlmzZqlzMxMderUSYcOHVJmZqYkKTg42Ok9wcHB1rzMzEx5e3urbt26ZcYEBQW5rDsoKMiKKUlSUpL1TA673a7Q0NBz2lYAAAAAAOCKwgYAAHArvXv31m233abWrVure/fuWr58uaTTt5wqYrPZnN5jjHGZVlzxmJLiz7acsWPHKicnx3rt2bOnXNsEAAAAAADKj8IGAABwa35+fmrdurV++OEH67kbxa+qyMrKsq7icDgcys/PV3Z2dpkxBw4ccFnXwYMHXa4GOZOPj49q167t9AIAAAAAAFWLwgYAAHBreXl52r59uxo0aKCwsDA5HA6tXLnSmp+fn6+1a9eqU6dOkqT27dvLy8vLKWb//v3aunWrFRMVFaWcnBxt3LjRitmwYYNycnKsGAAAAAAAUD08q7sBAAAAFTFmzBj17dtXDRs2VFZWll5++WUdOXJEgwcPls1mU3x8vBITExUeHq7w8HAlJiaqVq1aGjRokCTJbrdryJAhGj16tAIDAxUQEKAxY8ZYt7aSpObNm6tXr14aOnSoZsyYIUkaNmyYYmNjFRERUW3bDgAAAAAAKGwAAAA3s3fvXt1111367bffVL9+fXXs2FHp6elq1KiRJOmpp55Sbm6uRowYoezsbEVGRmrFihXy9/e3ljF58mR5enpqwIABys3NVbdu3TR37lx5eHhYMYsWLdKoUaMUExMjSerXr5+Sk5Mv7MYCAAAAAAAXNmOMqe5GuIMjR47IbrcrJyenyu6XvXTH/ipZDi4e/SMaVHcTAKBKnY/z35/J+dp/5BCXFvIHAJcicojKI39AeZA/ALgUVeQcyDM2AAAAAAAAAACA26CwAQAAAAAAAAAA3Ea1FzZ+/fVX3XPPPQoMDFStWrV09dVXa8uWLdZ8Y4wSEhIUEhIiX19fdenSRdu2bXNaRl5enkaOHKl69erJz89P/fr10969e51isrOzFRcXJ7vdLrvdrri4OB0+fPhCbCIAAAAAAKhmX3zxhfr27auQkBDZbDYtW7bMmnfy5Ek9/fTTat26tfz8/BQSEqJ7771X+/btc1oG/Q8AAFwcqrWwkZ2drc6dO8vLy0uffPKJvvvuO73++uuqU6eOFTNx4kRNmjRJycnJ2rRpkxwOh3r06KGjR49aMfHx8UpJSdGSJUu0bt06HTt2TLGxsSooKLBiBg0apIyMDKWmpio1NVUZGRmKi4u7kJsLAAAAAACqyfHjx9W2bVslJye7zPvjjz/01Vdf6YUXXtBXX32lpUuXaufOnerXr59THP0PAABcHKr14eHPPPOM/vOf/+jLL78scb4xRiEhIYqPj9fTTz8t6fToiODgYE2YMEHDhw9XTk6O6tevrwULFujOO++UJO3bt0+hoaH6+OOP1bNnT23fvl0tWrRQenq6IiMjJUnp6emKiorS999/r4iIiLO2lYeHozx4eBfc0RvZb1R3E1DFHqv7WJUtiwd/nhse/onyIH8AcCm62HMIm82mlJQU3XLLLaXGbNq0Sdddd51++eUXNWzY0K37HyTyh0sN+QPcFX0Ql57q6oOo1is2PvjgA3Xo0EF33HGHgoKC1K5dO82aNcuav2vXLmVmZiomJsaa5uPjo+joaK1fv16StGXLFp08edIpJiQkRK1atbJi0tLSZLfbraRCkjp27Ci73W7FFJeXl6cjR444vQAAAAAAwJ9DTk6ObDabdVcJ+h8AALh4VGth46efftK0adMUHh6uTz/9VA899JBGjRql+fPnS5IyMzMlScHBwU7vCw4OtuZlZmbK29tbdevWLTMmKCjIZf1BQUFWTHFJSUnW/TDtdrtCQ0PPbWMBAAAAAIBbOHHihJ555hkNGjTIGjFK/wMAABePai1sFBYW6pprrlFiYqLatWun4cOHa+jQoZo2bZpTnM1mc/rbGOMyrbjiMSXFl7WcsWPHKicnx3rt2bOnvJsFAAAAAADc1MmTJzVw4EAVFhbqrbfeOms8/Q8AAFx4ntW58gYNGqhFixZO05o3b6733ntPkuRwOCSdHvHQoMH/3TswKyvLuorD4XAoPz9f2dnZTqMmsrKy1KlTJyvmwIEDLus/ePCgy9UgRXx8fOTj43MOWwcAAAAAly7ukX1pqcr7Y7uzkydPasCAAdq1a5c+//xzp/t70/8AAMDFo1qv2OjcubN27NjhNG3nzp1q1KiRJCksLEwOh0MrV6605ufn52vt2rVW0tC+fXt5eXk5xezfv19bt261YqKiopSTk6ONGzdaMRs2bFBOTo4VAwAAAAAA/ryKiho//PCDVq1apcDAQKf59D8AAHDxqNYrNh5//HF16tRJiYmJGjBggDZu3KiZM2dq5syZkk5fvhkfH6/ExESFh4crPDxciYmJqlWrlgYNGiRJstvtGjJkiEaPHq3AwEAFBARozJgxat26tbp37y7p9FUgvXr10tChQzVjxgxJ0rBhwxQbG6uIiIjq2XgAAAAAAHDBHDt2TD/++KP1965du5SRkaGAgACFhITo9ttv11dffaWPPvpIBQUF1jMxAgIC5O3tTf8DAAAXkWotbFx77bVKSUnR2LFjNX78eIWFhWnKlCm6++67rZinnnpKubm5GjFihLKzsxUZGakVK1bI39/fipk8ebI8PT01YMAA5ebmqlu3bpo7d648PDysmEWLFmnUqFGKiYmRJPXr10/JyckXbmMBAAAAAEC12bx5s7p27Wr9/cQTT0iSBg8erISEBH3wwQeSpKuvvtrpfatXr1aXLl0k0f8AAMDFwmaMMdXdCHdw5MgR2e125eTkON1j81ws3bG/SpaDi0f/iAZnDwIuMtwf+9JTlffIPh/nvz+T87X/yCEuLeQPcFfkEJeWqn7GBjlE5ZE/oDzIH+CuyB8uPdXVB1Gtz9gAAAAAAAAAAACoCAobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC3QWEDAAAAAAAAAAC4DQobAAAAAAAAAADAbVDYAAAAAAAAAAAAboPCBgAAAAAAAAAAcBsUNgAAAAAAAAAAgNugsAEAAAAAAAAAANwGhQ0AAAAAAAAAAOA2KGwAAAAAAAAAAAC34VndDQBwbnLGjavuJqAK2V96qbqbAAAAAACAC/ofLj30QcCdccUGAAAAAAAAAABwG1yxAQAAAPzJMOLy0sOISwAAAPyZcMUGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtVGthIyEhQTabzenlcDis+cYYJSQkKCQkRL6+vurSpYu2bdvmtIy8vDyNHDlS9erVk5+fn/r166e9e/c6xWRnZysuLk52u112u11xcXE6fPjwhdhEAAAAAABwEfjiiy/Ut29fhYSEyGazadmyZU7z6YMAAMB9VPsVGy1bttT+/fut17fffmvNmzhxoiZNmqTk5GRt2rRJDodDPXr00NGjR62Y+Ph4paSkaMmSJVq3bp2OHTum2NhYFRQUWDGDBg1SRkaGUlNTlZqaqoyMDMXFxV3Q7QQAAAAAANXn+PHjatu2rZKTk0ucTx8EAADuo9oLG56ennI4HNarfv36kk6PlJgyZYqee+459e/fX61atdK8efP0xx9/aPHixZKknJwczZ49W6+//rq6d++udu3aaeHChfr222+1atUqSdL27duVmpqqf/zjH4qKilJUVJRmzZqljz76SDt27Ki27QYAAFUjKSlJNptN8fHx1jRGXAIAgOJ69+6tl19+Wf3793eZRx8EAADupdoLGz/88INCQkIUFhamgQMH6qeffpIk7dq1S5mZmYqJibFifXx8FB0drfXr10uStmzZopMnTzrFhISEqFWrVlZMWlqa7Ha7IiMjrZiOHTvKbrdbMSXJy8vTkSNHnF4AAODismnTJs2cOVNt2rRxms6ISwAAUBHV2QdB/wMAABVXrYWNyMhIzZ8/X59++qlmzZqlzMxMderUSYcOHVJmZqYkKTg42Ok9wcHB1rzMzEx5e3urbt26ZcYEBQW5rDsoKMiKKUlSUpI1OtNutys0NPScthUAAFStY8eO6e6779asWbOccgFGXAIAgIqqzj4I+h8AAKi4ai1s9O7dW7fddptat26t7t27a/ny5ZKkefPmWTE2m83pPcYYl2nFFY8pKf5syxk7dqxycnKs1549e8q1TQAA4MJ45JFH1KdPH3Xv3t1pOiMuAQBAZVVHHwT9DwAAVFy134rqTH5+fmrdurV++OEHORwOSXIZ0ZCVlWWNoHA4HMrPz1d2dnaZMQcOHHBZ18GDB11GYpzJx8dHtWvXdnoBAICLw5IlS/TVV18pKSnJZR4jLgEAQEVVZx8E/Q8AAFTcRVXYyMvL0/bt29WgQQOFhYXJ4XBo5cqV1vz8/HytXbtWnTp1kiS1b99eXl5eTjH79+/X1q1brZioqCjl5ORo48aNVsyGDRuUk5NjxQAAAPexZ88ePfbYY1q4cKFq1qxZahwjLgEAQHnRBwEAgHvxrM6VjxkzRn379lXDhg2VlZWll19+WUeOHNHgwYNls9kUHx+vxMREhYeHKzw8XImJiapVq5YGDRokSbLb7RoyZIhGjx6twMBABQQEaMyYMdatrSSpefPm6tWrl4YOHaoZM2ZIkoYNG6bY2FhFRERU27YDAIDK2bJli7KystS+fXtrWkFBgb744gslJydbz7/IzMxUgwYNrJjSRlyeedVGVlaW1elQ2RGXPj4+576RAACgyh07dkw//vij9feuXbuUkZGhgIAANWzYkD4IAADcSLUWNvbu3au77rpLv/32m+rXr6+OHTsqPT1djRo1kiQ99dRTys3N1YgRI5Sdna3IyEitWLFC/v7+1jImT54sT09PDRgwQLm5uerWrZvmzp0rDw8PK2bRokUaNWqUdR/tfv36KTk5+cJuLAAAqBLdunXTt99+6zTt/vvvV7NmzfT000+rSZMm1ojLdu3aSfq/EZcTJkyQ5DzicsCAAZL+b8TlxIkTJTmPuLzuuuskMeISAAB3tnnzZnXt2tX6+4knnpAkDR48WHPnzqUPAgAAN1KthY0lS5aUOd9msykhIUEJCQmlxtSsWVNTp07V1KlTS40JCAjQwoULK9tMAABwEfH391erVq2cpvn5+SkwMNCazohLAABQXJcuXWSMKXU+fRAAALiPai1sAAAAnA+MuAQAAAAA4NJFYQMAALi9NWvWOP3NiEsAAAAAAC5dNaq7AQAAAAAAAAAAAOVFYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdRqcJGkyZNdOjQIZfphw8fVpMmTc65UQAA4NJD/gAAACqK/AEAAJSkUoWNn3/+WQUFBS7T8/Ly9Ouvv55zowAAwKWH/AEAAFQU+QMAACiJZ0WCP/jgA+v/P/30U9ntduvvgoICffbZZ2rcuHGVNQ4AALg/8gcAAFBR5A8AAKAsFSps3HLLLZIkm82mwYMHO83z8vJS48aN9frrr1dZ4wAAgPsjfwAAABVF/gAAAMpSocJGYWGhJCksLEybNm1SvXr1zkujAADApYP8AQAAVBT5AwAAKEuFChtFdu3aVdXtAAAAlzjyBwAAUFHkDwAAoCSVKmxI0meffabPPvtMWVlZ1kiKIm+//fY5NwwAAFx6yB8AAEBFkT8AAIDiKlXYGDdunMaPH68OHTqoQYMGstlsVd0uAABwiSF/AAAAFUX+AAAASlKpwsb06dM1d+5cxcXFVXV7AADAJYr8AQAAVBT5AwAAKEmNyrwpPz9fnTp1quq2AACASxj5AwAAqCjyBwAAUJJKFTYefPBBLV68uKrbAgAALmHkDwAAoKLIHwAAQEkqdSuqEydOaObMmVq1apXatGkjLy8vp/mTJk2qksYBAIBLB/kDAACoKPIHAABQkkoVNr755htdffXVkqStW7c6zeNBXgAAoCTkDwAAoKLIHwAAQEkqVdhYvXp1VbcDAABc4sgfAABARZE/AACAklTqGRsAAAAAAAAAAADVoVJXbHTt2rXMSz4///zzSjcIAABcmsgfAABARZE/AACAklSqsFF0f8siJ0+eVEZGhrZu3arBgwdXRbsAAMAlhvwBAABUFPkDAAAoSaUKG5MnTy5xekJCgo4dO3ZODQIAAJcm8gcAAFBR5A8AAKAkVfqMjXvuuUdvv/12VS4SAABc4sgfAABARZE/AADw51alhY20tDTVrFmzKhcJAAAuceQPAACgosgfAAD4c6vUraj69+/v9LcxRvv379fmzZv1wgsvVEnDAADApYX8AQAAVBT5AwAAKEmlCht2u93p7xo1aigiIkLjx49XTExMlTQMAABcWsgfAABARZE/AACAklSqsDFnzpyqbgcAALjEkT8AAICKIn8AAAAlOadnbGzZskULFy7UokWL9N///vecGpKUlCSbzab4+HhrmjFGCQkJCgkJka+vr7p06aJt27Y5vS8vL08jR45UvXr15Ofnp379+mnv3r1OMdnZ2YqLi5PdbpfdbldcXJwOHz58Tu0FAACVU5X5AwAA+HO4EPnDqVOn9PzzzyssLEy+vr5q0qSJxo8fr8LCQiumqvopAADAualUYSMrK0s33nijrr32Wo0aNUqPPvqo2rdvr27duungwYMVXt6mTZs0c+ZMtWnTxmn6xIkTNWnSJCUnJ2vTpk1yOBzq0aOHjh49asXEx8crJSVFS5Ys0bp163Ts2DHFxsaqoKDAihk0aJAyMjKUmpqq1NRUZWRkKC4urjKbDgAAKqmq8wcAAHDpu5D5w4QJEzR9+nQlJydr+/btmjhxol577TVNnTrViqmqfgoAAHBuKlXYGDlypI4cOaJt27bp999/V3Z2trZu3aojR45o1KhRFVrWsWPHdPfdd2vWrFmqW7euNd0YoylTpui5555T//791apVK82bN09//PGHFi9eLEnKycnR7Nmz9frrr6t79+5q166dFi5cqG+//VarVq2SJG3fvl2pqan6xz/+oaioKEVFRWnWrFn66KOPtGPHjspsPgAAqISqzB8AAMCfw4XMH9LS0nTzzTerT58+aty4sW6//XbFxMRo8+bNkqqunwIAAJy7ShU2UlNTNW3aNDVv3tya1qJFC7355pv65JNPKrSsRx55RH369FH37t2dpu/atUuZmZlODwPz8fFRdHS01q9fL+n0pagnT550igkJCVGrVq2smLS0NNntdkVGRloxHTt2lN1ut2IAAMD5V5X5AwAA+HO4kPnD9ddfr88++0w7d+6UJH399ddat26dbrrpJklV108BAADOXaUeHl5YWCgvLy+X6V5eXk73njybJUuW6KuvvtKmTZtc5mVmZkqSgoODnaYHBwfrl19+sWK8vb2drvQoiil6f2ZmpoKCglyWHxQUZMWUJC8vT3l5edbfR44cKedWAQCAklRV/gAAAP48LmT+8PTTTysnJ0fNmjWTh4eHCgoK9Morr+iuu+6SVHX9FMXR/wAAQMVV6oqNG2+8UY899pj27dtnTfv111/1+OOPq1u3buVaxp49e/TYY49p4cKFqlmzZqlxNpvN6W9jjMu04orHlBR/tuUkJSVZDxu32+0KDQ0tc50AAKBsVZE/AACAP5cLmT+8++67WrhwoRYvXqyvvvpK8+bN09/+9jfNmzfPKa4q+inORP8DAAAVV6nCRnJyso4eParGjRuradOmuvLKKxUWFqajR486PVSrLFu2bFFWVpbat28vT09PeXp6au3atfr73/8uT09PawRE8RENWVlZ1jyHw6H8/HxlZ2eXGXPgwAGX9R88eNBllMWZxo4dq5ycHOu1Z8+ecm0XAAAoWVXkDwAA4M/lQuYPTz75pJ555hkNHDhQrVu3VlxcnB5//HElJSVJOt2/IJ17P0Vx9D8AAFBxlboVVWhoqL766iutXLlS33//vYwxatGihctzMsrSrVs3ffvtt07T7r//fjVr1kxPP/20mjRpIofDoZUrV6pdu3aSpPz8fK1du1YTJkyQJLVv315eXl5auXKlBgwYIEnav3+/tm7dqokTJ0qSoqKilJOTo40bN+q6666TJG3YsEE5OTnq1KlTqe3z8fGRj49P+XcKAAAoU1XkDwAA4M/lQuYPf/zxh2rUcB7/6eHhYd3yKiwsrEr6KYqj/wEAgIqrUGHj888/16OPPqr09HTVrl1bPXr0UI8ePSRJOTk5atmypaZPn66//OUvZ12Wv7+/WrVq5TTNz89PgYGB1vT4+HglJiYqPDxc4eHhSkxMVK1atTRo0CBJkt1u15AhQzR69GgFBgYqICBAY8aMUevWra0kp3nz5urVq5eGDh2qGTNmSJKGDRum2NhYRUREVGTzAQBAJVRl/gAAAP4cqiN/6Nu3r1555RU1bNhQLVu21H//+19NmjRJDzzwgKTTt6Cqin4KAABw7ipU2JgyZYqGDh2q2rVru8yz2+0aPny4Jk2aVGWJxVNPPaXc3FyNGDFC2dnZioyM1IoVK+Tv72/FTJ48WZ6enhowYIByc3PVrVs3zZ07Vx4eHlbMokWLNGrUKMXExEiS+vXrp+Tk5CppIwAAKNuFzh8AAID7q478YerUqXrhhRc0YsQIZWVlKSQkRMOHD9eLL75oxVRVPwUAADg3FSpsfP3119bllSWJiYnR3/72t0o3Zs2aNU5/22w2JSQkKCEhodT31KxZU1OnTi3z3poBAQFauHBhpdsFAAAq73znDwAA4NJTHfmDv7+/pkyZoilTppQaU1X9FAAA4NxU6OHhBw4ckJeXV6nzPT09dfDgwXNuFAAAuHSQPwAAgIoifwAAAGWpUGHj8ssvd3ng95m++eYbNWjQ4JwbBQAALh3kDwAAoKLIHwAAQFkqVNi46aab9OKLL+rEiRMu83Jzc/XSSy8pNja2yhoHAADcH/kDAACoKPIHAABQlgo9Y+P555/X0qVLddVVV+nRRx9VRESEbDabtm/frjfffFMFBQV67rnnzldbAQCAGyJ/AAAAFUX+AAAAylKhwkZwcLDWr1+vhx9+WGPHjpUxRtLph2f17NlTb731loKDg89LQwEAgHsifwAAABVF/gAAAMpSocKGJDVq1Egff/yxsrOz9eOPP8oYo/DwcNWtW/d8tA8AAFwCyB8AAEBFkT8AAIDSVOgZG2eqW7eurr32Wl133XUkFQAAoFyqIn+YNm2a2rRpo9q1a6t27dqKiorSJ598Ys03xighIUEhISHy9fVVly5dtG3bNqdl5OXlaeTIkapXr578/PzUr18/7d271ykmOztbcXFxstvtstvtiouL0+HDhyvVZgAAUHn0PwAAgOIqXdgAAACoDldccYVeffVVbd68WZs3b9aNN96om2++2SpeTJw4UZMmTVJycrI2bdokh8OhHj166OjRo9Yy4uPjlZKSoiVLlmjdunU6duyYYmNjVVBQYMUMGjRIGRkZSk1NVWpqqjIyMhQXF3fBtxcAAAAAADir8K2oAAAAqlPfvn2d/n7llVc0bdo0paenq0WLFpoyZYqee+459e/fX5I0b948BQcHa/HixRo+fLhycnI0e/ZsLViwQN27d5ckLVy4UKGhoVq1apV69uyp7du3KzU1Venp6YqMjJQkzZo1S1FRUdqxY4ciIiIu7EYDAAAAAAALV2wAAAC3VVBQoCVLluj48eOKiorSrl27lJmZqZiYGCvGx8dH0dHRWr9+vSRpy5YtOnnypFNMSEiIWrVqZcWkpaXJbrdbRQ1J6tixo+x2uxVTkry8PB05csTpBQAAAAAAqhaFDQAA4Ha+/fZbXXbZZfLx8dFDDz2klJQUtWjRQpmZmZKk4OBgp/jg4GBrXmZmpry9vV3u0V08JigoyGW9QUFBVkxJkpKSrGdy2O12hYaGntN2AgAAAAAAVxQ2AACA24mIiFBGRobS09P18MMPa/Dgwfruu++s+TabzSneGOMyrbjiMSXFn205Y8eOVU5OjvXas2dPeTcJAAAAAACUE4UNAADgdry9vXXllVeqQ4cOSkpKUtu2bfXGG2/I4XBIkstVFVlZWdZVHA6HQ/n5+crOzi4z5sCBAy7rPXjwoMvVIGfy8fFR7dq1nV4AAAAAAKBqUdgAAABuzxijvLw8hYWFyeFwaOXKlda8/Px8rV27Vp06dZIktW/fXl5eXk4x+/fv19atW62YqKgo5eTkaOPGjVbMhg0blJOTY8UAAAAAAIDq4VndDQAAAKiIZ599Vr1791ZoaKiOHj2qJUuWaM2aNUpNTZXNZlN8fLwSExMVHh6u8PBwJSYmqlatWho0aJAkyW63a8iQIRo9erQCAwMVEBCgMWPGqHXr1urevbskqXnz5urVq5eGDh2qGTNmSJKGDRum2NhYRUREVNu2AwAAAAAAChsAAMDNHDhwQHFxcdq/f7/sdrvatGmj1NRU9ejRQ5L01FNPKTc3VyNGjFB2drYiIyO1YsUK+fv7W8uYPHmyPD09NWDAAOXm5qpbt26aO3euPDw8rJhFixZp1KhRiomJkST169dPycnJF3ZjAQAAAACACwobAADArcyePbvM+TabTQkJCUpISCg1pmbNmpo6daqmTp1aakxAQIAWLlxY2WYCAAAAAIDzhGdsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt1GthY1p06apTZs2ql27tmrXrq2oqCh98skn1nxjjBISEhQSEiJfX1916dJF27Ztc1pGXl6eRo4cqXr16snPz0/9+vXT3r17nWKys7MVFxcnu90uu92uuLg4HT58+EJsIgAAAAAAcBO//vqr7rnnHgUGBqpWrVq6+uqrtWXLFmt+VfVTAACAc1OthY0rrrhCr776qjZv3qzNmzfrxhtv1M0332wlBRMnTtSkSZOUnJysTZs2yeFwqEePHjp69Ki1jPj4eKWkpGjJkiVat26djh07ptjYWBUUFFgxgwYNUkZGhlJTU5WamqqMjAzFxcVd8O0FAAAAAAAXp+zsbHXu3FleXl765JNP9N133+n1119XnTp1rJiq6qcAAADnxrM6V963b1+nv1955RVNmzZN6enpatGihaZMmaLnnntO/fv3lyTNmzdPwcHBWrx4sYYPH66cnBzNnj1bCxYsUPfu3SVJCxcuVGhoqFatWqWePXtq+/btSk1NVXp6uiIjIyVJs2bNUlRUlHbs2KGIiIgLu9EAAAAAAOCiM2HCBIWGhmrOnDnWtMaNG1v/b4ypkn4KAABw7i6aZ2wUFBRoyZIlOn78uKKiorRr1y5lZmYqJibGivHx8VF0dLTWr18vSdqyZYtOnjzpFBMSEqJWrVpZMWlpabLb7VZRQ5I6duwou91uxQAAAAAAgD+3Dz74QB06dNAdd9yhoKAgtWvXTrNmzbLmV1U/BQAAOHfVXtj49ttvddlll8nHx0cPPfSQUlJS1KJFC2VmZkqSgoODneKDg4OteZmZmfL29lbdunXLjAkKCnJZb1BQkBVTkry8PB05csTpBQAAAAAALk0//fSTpk2bpvDwcH366ad66KGHNGrUKM2fP1+Sqqyfojj6HwAAqLhqL2xEREQoIyND6enpevjhhzV48GB999131nybzeYUb4xxmVZc8ZiS4s+2nKSkJOth43a7XaGhoeXdJAAAAAAA4GYKCwt1zTXXKDExUe3atdPw4cM1dOhQTZs2zSmuKvopzkT/AwAAFVfthQ1vb29deeWV6tChg5KSktS2bVu98cYbcjgckuQyoiErK8saHeFwOJSfn6/s7OwyYw4cOOCy3oMHD7qMsjjT2LFjlZOTY7327NlzTtsJAAAAAAAuXg0aNFCLFi2cpjVv3ly7d++WpCrrpyiO/gcAACqu2gsbxRljlJeXp7CwMDkcDq1cudKal5+fr7Vr16pTp06SpPbt28vLy8spZv/+/dq6dasVExUVpZycHG3cuNGK2bBhg3JycqyYkvj4+Kh27dpOLwAAAAAAcGnq3LmzduzY4TRt586datSokSRVWT9FcfQ/AABQcZ7VufJnn31WvXv3VmhoqI4ePaolS5ZozZo1Sk1Nlc1mU3x8vBITExUeHq7w8HAlJiaqVq1aGjRokCTJbrdryJAhGj16tAIDAxUQEKAxY8aodevW6t69u6TToyt69eqloUOHasaMGZKkYcOGKTY2VhEREdW27QAAAAAA4OLx+OOPq1OnTkpMTNSAAQO0ceNGzZw5UzNnzpSkKuunAAAA565aCxsHDhxQXFyc9u/fL7vdrjZt2ig1NVU9evSQJD311FPKzc3ViBEjlJ2drcjISK1YsUL+/v7WMiZPnixPT08NGDBAubm56tatm+bOnSsPDw8rZtGiRRo1apRiYmIkSf369VNycvKF3VgAAAAAAHDRuvbaa5WSkqKxY8dq/PjxCgsL05QpU3T33XdbMVXVTwEAAM5NtRY2Zs+eXeZ8m82mhIQEJSQklBpTs2ZNTZ06VVOnTi01JiAgQAsXLqxsMwEAAAAAwJ9AbGysYmNjS51fVf0UAADg3Fx0z9gAAAAAAAAAAAAoDYUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAAAAAAAAAwG1Q2AAAAAAAAAAAAG6DwgYAAAAAAAAAAHAbFDYAAAAAAAAAAIDboLABAAAAAAAAAADcBoUNAAAAAAAAAADgNihsAAAAAAAAAAAAt0FhAwAAAAAAAAAAuA0KGwAAwK0kJSXp2muvlb+/v4KCgnTLLbdox44dTjHGGCUkJCgkJES+vr7q0qWLtm3b5hSTl5enkSNHql69evLz81O/fv20d+9ep5js7GzFxcXJbrfLbrcrLi5Ohw8fPt+bCAAAAAAAykBhAwAAuJW1a9fqkUceUXp6ulauXKlTp04pJiZGx48ft2ImTpyoSZMmKTk5WZs2bZLD4VCPHj109OhRKyY+Pl4pKSlasmSJ1q1bp2PHjik2NlYFBQVWzKBBg5SRkaHU1FSlpqYqIyNDcXFxF3R7AQAAAACAM8/qbgAAAEBFpKamOv09Z84cBQUFacuWLbrhhhtkjNGUKVP03HPPqX///pKkefPmKTg4WIsXL9bw4cOVk5Oj2bNna8GCBerevbskaeHChQoNDdWqVavUs2dPbd++XampqUpPT1dkZKQkadasWYqKitKOHTsUERFxYTccAAAAAABI4ooNAADg5nJyciRJAQEBkqRdu3YpMzNTMTExVoyPj4+io6O1fv16SdKWLVt08uRJp5iQkBC1atXKiklLS5PdbreKGpLUsWNH2e12KwYAAAAAAFx4XLEBAADcljFGTzzxhK6//nq1atVKkpSZmSlJCg4OdooNDg7WL7/8YsV4e3urbt26LjFF78/MzFRQUJDLOoOCgqyY4vLy8pSXl2f9feTIkUpuGQAAAAAAKA1XbAAAALf16KOP6ptvvtE777zjMs9mszn9bYxxmVZc8ZiS4staTlJSkvWgcbvdrtDQ0PJsBgAAAAAAqAAKGwAAwC2NHDlSH3zwgVavXq0rrrjCmu5wOCTJ5aqKrKws6yoOh8Oh/Px8ZWdnlxlz4MABl/UePHjQ5WqQImPHjlVOTo712rNnT+U3EAAAAAAAlIjCBgAAcCvGGD366KNaunSpPv/8c4WFhTnNDwsLk8Ph0MqVK61p+fn5Wrt2rTp16iRJat++vby8vJxi9u/fr61bt1oxUVFRysnJ0caNG62YDRs2KCcnx4opzsfHR7Vr13Z6AQAAAACAqsUzNgAAgFt55JFHtHjxYr3//vvy9/e3rsyw2+3y9fWVzWZTfHy8EhMTFR4ervDwcCUmJqpWrVoaNGiQFTtkyBCNHj1agYGBCggI0JgxY9S6dWt1795dktS8eXP16tVLQ4cO1YwZMyRJw4YNU2xsrCIiIqpn4wEAAAAAAIUNAADgXqZNmyZJ6tKli9P0OXPm6L777pMkPfXUU8rNzdWIESOUnZ2tyMhIrVixQv7+/lb85MmT5enpqQEDBig3N1fdunXT3Llz5eHhYcUsWrRIo0aNUkxMjCSpX79+Sk5OPr8bCAAAAAAAykRhAwAAuBVjzFljbDabEhISlJCQUGpMzZo1NXXqVE2dOrXUmICAAC1cuLAyzQQAAAAAAOcJz9gAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ2AAAAAAAAAACA26CwAQAAAAAAAAAA3AaFDQAAAAAAAAAA4DYobAAAAAAAAAAAALdBYQMAAAAAAAAAALgNChsAAAAAAAAAAMBtUNgAAAAAAAAAAABug8IGAAAAAAAAAABwGxQ28P/au/8or+o6f+DPEWRQHEaBZsbJsUUFs1AzTMUtgSSEI5KraUXN0TKtAI3FsnU9e5zqBK2VehbSzBA8IbK7LfZ7J2kF/IkiOaWu6x5PpHhi1GocfkgD6Of7R18+6zCgMjMw84HH45zPOd73fd3PvN+eO/A693kvFwAAAAAASkaPBhuzZ8/O+973vlRUVKSqqirnnntunn766XY1hUIhDQ0Nqa2tzUEHHZQxY8bkySefbFfT1taWyy+/PEOGDMmAAQMyefLkPP/88+1qWlpaUl9fn8rKylRWVqa+vj4vv/zynl4iAAAAUIJmz56dsrKyzJgxozjWXdcoAICu6dFgY8WKFZk2bVpWrlyZpUuXZtu2bRk/fnw2bdpUrLnuuuty/fXXZ+7cuVm1alVqamryoQ99KBs2bCjWzJgxI3fddVcWL16c+++/Pxs3bsykSZPy6quvFmumTJmSpqamNDY2prGxMU1NTamvr9+r6wUAAAB6v1WrVuV73/teTjjhhHbj3XWNAgDomh4NNhobG3PxxRfn3e9+d0488cTMnz8/zz33XFavXp3kr3dC3Hjjjbnmmmty3nnnZcSIEbn99tvzyiuvZNGiRUmS1tbWzJs3L9/+9rczbty4nHTSSVm4cGEef/zx/OpXv0qSPPXUU2lsbMz3v//9jBo1KqNGjcqtt96an/3sZx2eEAEAAAD2Xxs3bswnPvGJ3HrrrTnssMOK4911jQIA6Lpe9Y6N1tbWJMmgQYOSJGvWrElzc3PGjx9frCkvL8/o0aPz4IMPJklWr16drVu3tqupra3NiBEjijUPPfRQKisrc+qppxZrTjvttFRWVhZrAAAAAKZNm5azzz4748aNazfeXdcoAICu69vTE9iuUChk5syZef/7358RI0YkSZqbm5Mk1dXV7Wqrq6vz7LPPFmv69evX7i6K7TXbj29ubk5VVVWHn1lVVVWs2VFbW1va2tqK2+vXr+/kygAAAIBSsHjx4vz617/OqlWrOuzrrmsUO3L9AQB2X695YmP69On57W9/mzvvvLPDvrKysnbbhUKhw9iOdqzZWf0bfc/s2bOLLxqvrKxMXV3dW1kGAAAAUILWrl2bL3zhC1m4cGH69++/y7ruuEbxeq4/AMDu6xXBxuWXX56f/OQnWbZsWY444ojieE1NTZJ0uKvhxRdfLN4hUVNTky1btqSlpeUNa1544YUOP/ell17qcKfFdldffXVaW1uLn7Vr13Z+gQAAAECvtnr16rz44osZOXJk+vbtm759+2bFihX5l3/5l/Tt27d4/aCr1yh25PoDAOy+Hg02CoVCpk+fniVLluSee+7J0KFD2+0fOnRoampqsnTp0uLYli1bsmLFipx++ulJkpEjR+bAAw9sV7Nu3bo88cQTxZpRo0altbU1jzzySLHm4YcfTmtra7FmR+Xl5Rk4cGC7DwAAALBvOvPMM/P444+nqamp+Dn55JPziU98Ik1NTTnqqKO65RrFjlx/AIDd16Pv2Jg2bVoWLVqUH//4x6moqCje9VBZWZmDDjooZWVlmTFjRmbNmpVhw4Zl2LBhmTVrVg4++OBMmTKlWHvJJZfkyiuvzODBgzNo0KB88YtfzPHHH1980ddxxx2XCRMm5NJLL80tt9ySJLnssssyadKkHHvssT2zeAAAAKDXqKioKL7zc7sBAwZk8ODBxfHuuEYBAHRdjwYbN998c5JkzJgx7cbnz5+fiy++OEly1VVXZfPmzZk6dWpaWlpy6qmn5u67705FRUWx/oYbbkjfvn1z4YUXZvPmzTnzzDOzYMGC9OnTp1hzxx135Iorrsj48eOTJJMnT87cuXP37AIBAACAfUZ3XaMAALqmR4ONQqHwpjVlZWVpaGhIQ0PDLmv69++fOXPmZM6cObusGTRoUBYuXNiZaQIAAAD7oeXLl7fb7q5rFABA1/SKl4cDAAAAAAC8FYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAErKvffem3POOSe1tbUpKyvLj370o3b7C4VCGhoaUltbm4MOOihjxozJk08+2a6mra0tl19+eYYMGZIBAwZk8uTJef7559vVtLS0pL6+PpWVlamsrEx9fX1efvnlPbw6AAAA4M0INgCAkrJp06aceOKJmTt37k73X3fddbn++uszd+7crFq1KjU1NfnQhz6UDRs2FGtmzJiRu+66K4sXL87999+fjRs3ZtKkSXn11VeLNVOmTElTU1MaGxvT2NiYpqam1NfX7/H1AQAAAG+sb09PAABgd0ycODETJ07c6b5CoZAbb7wx11xzTc4777wkye23357q6uosWrQon/3sZ9Pa2pp58+blBz/4QcaNG5ckWbhwYerq6vKrX/0qZ511Vp566qk0NjZm5cqVOfXUU5Mkt956a0aNGpWnn346xx577N5ZLAAAANCBJzYAgH3GmjVr0tzcnPHjxxfHysvLM3r06Dz44INJktWrV2fr1q3tamprazNixIhizUMPPZTKyspiqJEkp512WiorK4s1AAAAQM/wxAYAsM9obm5OklRXV7cbr66uzrPPPlus6devXw477LAONduPb25uTlVVVYfvr6qqKtbsTFtbW9ra2orb69ev79xCAAAAgF3yxAYAsM8pKytrt10oFDqM7WjHmp3Vv9n3zJ49u/iy8crKytTV1e3mzAEAAIA3I9gAAPYZNTU1SdLhqYoXX3yx+BRHTU1NtmzZkpaWljeseeGFFzp8/0svvdThaZDXu/rqq9Pa2lr8rF27tkvrAQAAADoSbAAA+4yhQ4empqYmS5cuLY5t2bIlK1asyOmnn54kGTlyZA488MB2NevWrcsTTzxRrBk1alRaW1vzyCOPFGsefvjhtLa2Fmt2pry8PAMHDmz3AQAAALqXd2wAACVl48aNeeaZZ4rba9asSVNTUwYNGpQjjzwyM2bMyKxZszJs2LAMGzYss2bNysEHH5wpU6YkSSorK3PJJZfkyiuvzODBgzNo0KB88YtfzPHHH59x48YlSY477rhMmDAhl156aW655ZYkyWWXXZZJkybl2GOP3fuLBgAAAIoEGwBASXn00UczduzY4vbMmTOTJBdddFEWLFiQq666Kps3b87UqVPT0tKSU089NXfffXcqKiqKx9xwww3p27dvLrzwwmzevDlnnnlmFixYkD59+hRr7rjjjlxxxRUZP358kmTy5MmZO3fuXlolAAAAsCuCDQCgpIwZMyaFQmGX+8vKytLQ0JCGhoZd1vTv3z9z5szJnDlzdlkzaNCgLFy4sCtTBQAAAPYA79gAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAktGjwca9996bc845J7W1tSkrK8uPfvSjdvsLhUIaGhpSW1ubgw46KGPGjMmTTz7ZrqatrS2XX355hgwZkgEDBmTy5Ml5/vnn29W0tLSkvr4+lZWVqaysTH19fV5++eU9vDoAAACgVMyePTvve9/7UlFRkaqqqpx77rl5+umn29V013UKAKBrejTY2LRpU0488cTMnTt3p/uvu+66XH/99Zk7d25WrVqVmpqafOhDH8qGDRuKNTNmzMhdd92VxYsX5/7778/GjRszadKkvPrqq8WaKVOmpKmpKY2NjWlsbExTU1Pq6+v3+PoAAACA0rBixYpMmzYtK1euzNKlS7Nt27aMHz8+mzZtKtZ013UKAKBr+vbkD584cWImTpy4032FQiE33nhjrrnmmpx33nlJkttvvz3V1dVZtGhRPvvZz6a1tTXz5s3LD37wg4wbNy5JsnDhwtTV1eVXv/pVzjrrrDz11FNpbGzMypUrc+qppyZJbr311owaNSpPP/10jj322L2zWAAAAKDXamxsbLc9f/78VFVVZfXq1TnjjDO67ToFANB1vfYdG2vWrElzc3PGjx9fHCsvL8/o0aPz4IMPJklWr16drVu3tqupra3NiBEjijUPPfRQKisri6FGkpx22mmprKws1gAAAAC8Xmtra5Jk0KBBSbrvOgUA0HU9+sTGG2lubk6SVFdXtxuvrq7Os88+W6zp169fDjvssA41249vbm5OVVVVh++vqqoq1uxMW1tb2traitvr16/v3EIAAACAklIoFDJz5sy8//3vz4gRI5J033WKHbn+AAC7r9c+sbFdWVlZu+1CodBhbEc71uys/s2+Z/bs2cWXjVdWVqaurm43Zw4AAACUounTp+e3v/1t7rzzzg77uuM6xeu5/gAAu6/XBhs1NTVJ0uGOhhdffLF4d0RNTU22bNmSlpaWN6x54YUXOnz/Sy+91OEui9e7+uqr09raWvysXbu2S+sBAAAAer/LL788P/nJT7Js2bIcccQRxfHuuk6xI9cfAGD39dpgY+jQoampqcnSpUuLY1u2bMmKFSty+umnJ0lGjhyZAw88sF3NunXr8sQTTxRrRo0aldbW1jzyyCPFmocffjitra3Fmp0pLy/PwIED230AAACAfVOhUMj06dOzZMmS3HPPPRk6dGi7/d11nWJHrj8AwO7r0XdsbNy4Mc8880xxe82aNWlqasqgQYNy5JFHZsaMGZk1a1aGDRuWYcOGZdasWTn44IMzZcqUJEllZWUuueSSXHnllRk8eHAGDRqUL37xizn++OMzbty4JMlxxx2XCRMm5NJLL80tt9ySJLnssssyadKkHHvssXt/0QAAAECvM23atCxatCg//vGPU1FRUXwyo7KyMgcddFDKysq65ToFANB1PRpsPProoxk7dmxxe+bMmUmSiy66KAsWLMhVV12VzZs3Z+rUqWlpacmpp56au+++OxUVFcVjbrjhhvTt2zcXXnhhNm/enDPPPDMLFixInz59ijV33HFHrrjiiowfPz5JMnny5MydO3cvrRIAAADo7W6++eYkyZgxY9qNz58/PxdffHGSdNt1CgCga3o02BgzZkwKhcIu95eVlaWhoSENDQ27rOnfv3/mzJmTOXPm7LJm0KBBWbhwYVemCgAAAOzD3uj6xHbddZ0CAOiaXvuODQAAAAAAgB0JNgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg0AAAAAAKBkCDYAAAAAAICSIdgAAAAAAABKhmADAAAAAAAoGYINAAAAAACgZAg2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJKxXwUbN910U4YOHZr+/ftn5MiRue+++3p6SgBAL6d/AAA6Qw8BAHvOfhNs/Ou//mtmzJiRa665Jo899lg+8IEPZOLEiXnuued6emoAQC+lfwAAOkMPAQB71n4TbFx//fW55JJL8pnPfCbHHXdcbrzxxtTV1eXmm2/u6akBAL2U/gEA6Aw9BADsWftFsLFly5asXr0648ePbzc+fvz4PPjggz00KwCgN9M/AACdoYcAgD2vb09PYG/44x//mFdffTXV1dXtxqurq9Pc3LzTY9ra2tLW1lbcbm1tTZKsX7++2+b1ysYN3fZd9A7r1w/Y+z/zL3/Z6z+TPaesG/+Meav+st45tK9Z36f7zqPtf+8VCoVu+85S0Vv7h0QPsa/RP9Ad9BB0VXf2D4keYnd6CP0DnaF/oDvoH+gOPXUNYr8INrYrKytrt10oFDqMbTd79ux85Stf6TBeV1e3R+YGkCT5xjd6egbsA/4h/9Dt37lhw4ZUVlZ2+/eWAv0DUBL0EHTRnugfEj3E6+2qh9A/AD1G/0A36KlrEPtFsDFkyJD06dOnw50RL774Yoc7KLa7+uqrM3PmzOL2a6+9lj//+c8ZPHjwLi9m0NH69etTV1eXtWvXZuDAgT09HUqU84ju4DzqnEKhkA0bNqS2tranp7LX6R96lt9Zuso5RHdwHnWeHuKt9xD6h+7jd5bu4Dyiq5xDnbc7/cN+EWz069cvI0eOzNKlS/N3f/d3xfGlS5fmwx/+8E6PKS8vT3l5ebuxQw89dE9Oc582cOBAv8h0mfOI7uA82n37612W+ofewe8sXeUcojs4jzpHD/HWegj9Q/fzO0t3cB7RVc6hznmr/cN+EWwkycyZM1NfX5+TTz45o0aNyve+970899xz+dznPtfTUwMAein9AwDQGXoIANiz9ptg46Mf/Wj+9Kc/5atf/WrWrVuXESNG5Be/+EXe8Y539PTUAIBeSv8AAHSGHgIA9qz9JthIkqlTp2bq1Kk9PY39Snl5ea699toOj9XC7nAe0R2cR3SW/qFn+J2lq5xDdAfnEV2hh9j7/M7SHZxHdJVzaO8oKxQKhZ6eBAAAAAAAwFtxQE9PAAAAAAAA4K0SbAAAAAAAACVDsAEAAAAAAJQMwQa77eKLL05ZWVmHz4QJE9rVzZo1K3369Mk3vvGNDt+xYMGCdscefvjhufDCC7NmzZq9tQx62MUXX5xzzz23w/jy5ctTVlaWl19+ufjf2z9ve9vbMnHixPzmN78p1o8ZMyYzZszYexOnR23/8+dzn/tch31Tp05NWVlZLr744nz3u99NRUVFtm3bVty/cePGHHjggfnABz7Q7rj77rsvZWVl+d///d8kyWOPPZZJkyalqqoq/fv3z9/8zd/kox/9aP74xz/u2cXBfkAPQVfpH+gM/QOUNv0D3UEPwe7SP/R+gg06ZcKECVm3bl27z5133tmuZv78+bnqqqty22237fQ7Bg4cmHXr1uUPf/hDFi1alKampkyePDmvvvrq3lgCJeTpp5/OunXr8vOf/zwtLS2ZMGFCWltbe3pa9JC6urosXrw4mzdvLo795S9/yZ133pkjjzwySTJ27Nhs3Lgxjz76aLHmvvvuS01NTVatWpVXXnmlOL58+fLU1tZm+PDhefHFFzNu3LgMGTIkv/zlL/PUU0/ltttuy+GHH97uGKDz9BDsLfoHXk//AKVN/8DepIdgO/1D7ybYoFPKy8tTU1PT7nPYYYcV969YsSKbN2/OV7/61WzatCn33ntvh+8oKytLTU1NDj/88IwdOzbXXnttnnjiiTzzzDN7cymUgKqqqtTU1OSUU07Jt7/97TQ3N2flypU9PS16yHvf+94ceeSRWbJkSXFsyZIlqaury0knnZQkOfbYY1NbW5vly5cXa5YvX54Pf/jDOfroo/Pggw+2Gx87dmyS5MEHH8z69evz/e9/PyeddFKGDh2aD37wg7nxxhuLTQvQNXoI9hb9A6+nf4DSpn9gb9JDsJ3+oXcTbLBHzJs3Lx//+Mdz4IEH5uMf/3jmzZv3psccdNBBSZKtW7fu6elRwpwnJMmnPvWpzJ8/v7h922235dOf/nS7mjFjxmTZsmXF7WXLlmXMmDEZPXp0cXzLli156KGHio1FTU1Ntm3blrvuuiuFQmEvrATYkR6CPcE5QqJ/gH2Z/oE9xXmC/qH3EmzQKT/72c9yyCGHtPt87WtfS5KsX78+//Ef/5FPfvKTSZJPfvKT+eEPf5j169fv8vuef/75fPOb38wRRxyR4cOH75U10PN2dh5NnDhxl/V/+tOf8pWvfCUVFRU55ZRT9uJM6W3q6+tz//335/e//32effbZPPDAA8U/c7YbM2ZMHnjggWzbti0bNmzIY489ljPOOCOjR48u3kmxcuXKbN68udhYnHbaafnHf/zHTJkyJUOGDMnEiRPzzW9+My+88MLeXiLss/QQdJX+gc7SP0Dp0j/QHfQQdIb+offq29MToDSNHTs2N998c7uxQYMGJUkWLVqUo446KieeeGKS5D3veU+OOuqoLF68OJdddlmxvrW1NYccckgKhUJeeeWVvPe9782SJUvSr1+/vbcQetTOzqOHH364w18QRxxxRJJk06ZNGTZsWP793/89VVVVe22e9D5DhgzJ2Wefndtvvz2FQiFnn312hgwZ0q5m7Nix2bRpU1atWpWWlpYMHz48VVVVGT16dOrr67Np06YsX748Rx55ZI466qjicV//+tczc+bM3HPPPVm5cmW++93vZtasWbn33ntz/PHH7+2lwj5HD0FX6R/oLP0DlC79A91BD0Fn6B96L8EGnTJgwIAcc8wxO91322235cknn0zfvv93er322muZN29eu6aioqIiv/71r3PAAQekuro6AwYM2OPzpnfZ2Xn0/PPPd6i77777MnDgwLztbW/LwIED99b06OU+/elPZ/r06UmS73znOx32H3PMMTniiCOybNmytLS0ZPTo0Un++rjn0KFD88ADD2TZsmX54Ac/2OHYwYMH54ILLsgFF1yQ2bNn56STTsq3vvWt3H777Xt2UbAf0EPQVfoHukL/AKVJ/0B30EPQWfqH3kmwQbd6/PHH8+ijj2b58uXFuyeS5OWXX84ZZ5yRJ554IiNGjEiSHHDAAbtsTOD1hg4dmkMPPbSnp0EvM2HChGzZsiVJctZZZ+20ZuzYsVm+fHlaWlrypS99qTg+evTo/PKXv8zKlSvzqU996g1/Tr9+/XL00Udn06ZN3Td5oAM9BN1N/8DO6B9g36J/YE/QQ7Aj/UPvJNigU9ra2tLc3NxurG/fvpk3b15OOeWUnHHGGR2OGTVqVObNm5cbbrhhb02T/cRLL72UpqamdmM1NTWpqanpmQmxV/Tp0ydPPfVU8b93ZuzYsZk2bVq2bt1avGMi+Wtj8fnPfz5/+ctfiv++ZfLXf3N18eLF+djHPpbhw4enUCjkpz/9aX7xi1+0e1kY0Hl6CHoL/cP+Sf8ApUn/QG+ih9j/6B96J8EGndLY2JjDDz+83djQoUOzfv36fPnLX97pMeeff35mz56df/7nf94bU2Q/smjRoixatKjd2LXXXpuGhoaemRB7zZs9Fjx27Nhs3rw573znO1NdXV0cHz16dDZs2JCjjz46dXV1xfF3vetdOfjgg3PllVdm7dq1KS8vz7Bhw/L9738/9fX1e2wdsD/RQ9Bb6B/2X/oHKD36B3oTPcT+Sf/Q+5QVCoVCT08CAAAAAADgrTigpycAAAAAAADwVgk2AAAAAACAkiHYAAAAAAAASoZgAwAAAAAAKBmCDQAAAAAAoGQINgAAAAAAgJIh2AAAAAAAAEqGYAMAAAAAACgZgg2gU8rKyvKjH/2op6fRKQ0NDXnPe97Tpe/4/e9/n7KysjQ1NXXLnABgf6B/0D8AwO7SP+gfYGcEG0AHzc3Nufzyy3PUUUelvLw8dXV1Oeecc/Jf//VfPT21JMmYMWMyY8aMnp4GAPA6+gcAYHfpH4DO6tvTEwB6l9///vf527/92xx66KG57rrrcsIJJ2Tr1q355S9/mWnTpuV//ud/enqKAEAvo38AAHaX/gHoCk9sAO1MnTo1ZWVleeSRR/KRj3wkw4cPz7vf/e7MnDkzK1eu3OVxX/7ylzN8+PAcfPDBOeqoo/JP//RP2bp1a3H/b37zm4wdOzYVFRUZOHBgRo4cmUcffTRJ8uyzz+acc87JYYcdlgEDBuTd7353fvGLX3R6DW82l+1uueWW1NXV5eCDD84FF1yQl19+ud3++fPn57jjjkv//v3zzne+MzfddFOn5wQA+zL9w//RPwDAW6N/+D/6B9h9ntgAiv785z+nsbExX//61zNgwIAO+w899NBdHltRUZEFCxaktrY2jz/+eC699NJUVFTkqquuSpJ84hOfyEknnZSbb745ffr0SVNTUw488MAkybRp07Jly5bce++9GTBgQP77v/87hxxySKfX8WZzSZJnnnkm//Zv/5af/vSnWb9+fS655JJMmzYtd9xxR5Lk1ltvzbXXXpu5c+fmpJNOymOPPZZLL700AwYMyEUXXdTpuQHAvkb/oH8AgN2lf9A/QJcVAP6/hx9+uJCksGTJkjetTVK46667drn/uuuuK4wcObK4XVFRUViwYMFOa48//vhCQ0PDW57n6NGjC1/4whfecv2Oc7n22msLffr0Kaxdu7Y49p//+Z+FAw44oLBu3bpCoVAo1NXVFRYtWtTue772ta8VRo0aVSgUCoU1a9YUkhQee+yxtzwPANgX6R/0DwCwu/QP+gfoKk9sAEWFQiFJUlZWttvH/vCHP8yNN96YZ555Jhs3bsy2bdsycODA4v6ZM2fmM5/5TH7wgx9k3LhxueCCC3L00UcnSa644op8/vOfz913351x48bl/PPPzwknnNDpdbzZXJLkyCOPzBFHHFHcHjVqVF577bU8/fTT6dOnT9auXZtLLrkkl156abFm27Ztqays7PS8AGBfpH/QPwDA7tI/6B+gq7xjAygaNmxYysrK8tRTT+3WcStXrszHPvaxTJw4MT/72c/y2GOP5ZprrsmWLVuKNQ0NDXnyySdz9tln55577sm73vWu3HXXXUmSz3zmM/nd736X+vr6PP744zn55JMzZ86cTq3hrcxlZ7Y3U2VlZXnttdeS/PVx0KampuLniSeeeMN/5xMA9kf6B/0DAOwu/YP+AbpKsAEUDRo0KGeddVa+853vZNOmTR327/hyq+0eeOCBvOMd78g111yTk08+OcOGDcuzzz7boW748OH5+7//+9x9990577zzMn/+/OK+urq6fO5zn8uSJUty5ZVX5tZbb+3UGt7qXJ577rn84Q9/KG4/9NBDOeCAAzJ8+PBUV1fn7W9/e373u9/lmGOOafcZOnRop+YFAPsq/YP+AQB2l/5B/wBd5Z+iAtq56aabcvrpp+eUU07JV7/61ZxwwgnZtm1bli5dmptvvnmnd1Mcc8wxee6557J48eK8733vy89//vPi3RBJsnnz5nzpS1/KRz7ykQwdOjTPP/98Vq1alfPPPz9JMmPGjEycODHDhw9PS0tL7rnnnhx33HFvOM+XXnopTU1N7cZqamredC7b9e/fPxdddFG+9a1vZf369bniiity4YUXpqamJslf7/C44oorMnDgwEycODFtbW159NFH09LSkpkzZ+7u/1YA2KfpH/QPALC79A/6B+iSHn7HB9AL/eEPfyhMmzat8I53vKPQr1+/wtvf/vbC5MmTC8uWLSvWZIeXd33pS18qDB48uHDIIYcUPvrRjxZuuOGGQmVlZaFQKBTa2toKH/vYxwp1dXWFfv36FWprawvTp08vbN68uVAoFArTp08vHH300YXy8vLC2972tkJ9fX3hj3/84y7nN3r06EKSDp9rr732TedSKPz15V0nnnhi4aabbirU1tYW+vfvXzjvvPMKf/7zn9v9nDvuuKPwnve8p9CvX7/CYYcdVjjjjDOKLzbz8i4AaE//8Ff6BwB46/QPf6V/gN1XVij8/7f1AAAAAAAA9HLesQEAAAAAAJQMwQYAAAAAAFAyBBsAAAAAAEDJEGwAAAAAAAAlQ7ABAAAAAACUDMEGAAAAAABQMgQbAAAAAABAyRBsAAAAAAAAJUOwAQAAAAAAlAzBBgAAAAAAUDIEGwAAAAAAQMkQbAAAAAAAACXj/wEvULqjHt8TowAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1600x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot  as plt \n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(y.sum().index, y.sum().values,color=['lightblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Overall Distribution (Before Splitting)')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.bar(y_train_nos.sum().index, y_train_nos.sum().values,color=['lightblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Distribution in Training Set (Without Stratification)')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(y_test.sum().index, y_test.sum().values,color=['lightblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Distribution in Testing Set (With Stratification)')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qEtGJ02o6bz"
      },
      "source": [
        "### D. Méthodes de vectorisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLX6LtFvo6bz"
      },
      "source": [
        "##### 1. Utiliser la méthode de fréquence lexicale et one-hot encoding pour vectoriser le dataset d’entrainement et du test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LjAAZUwTo6b0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# création d'un objet CountVectorizer pour effectuer la fréquence lexicale et l'encodage one-hot\n",
        "# (\n",
        "#    si binary=False => fréquence lexicale\n",
        "#    si binary=True => one-hot encoding\n",
        "#)\n",
        "# la matrice de fréquence lexicale contient les fréquences des mots,\n",
        "# tandis que la matrice d'encodage one-hot contient des vecteurs binaires indiquant la présence ou l'absence\n",
        "# de chaque mot.\n",
        "\n",
        "vectorizer = CountVectorizer(binary=False,analyzer= 'word', stop_words='english')\n",
        "vectorizer_onehot = CountVectorizer(binary=True , analyzer= 'word', stop_words='english')\n",
        "\n",
        "vectorizer.fit(X_train['text'])\n",
        "vectorizer_onehot.fit(X_train['text'])\n",
        "\n",
        "train_fl = vectorizer.transform(X_train['text'])\n",
        "test_fl = vectorizer.transform(X_test['text'])\n",
        "\n",
        "train_oneh = vectorizer_onehot.transform(X_train['text'])\n",
        "test_oneh = vectorizer_onehot.transform(X_test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "4hr7brU8o6b0",
        "outputId": "12c6f7ee-049e-4fbf-e63e-fc7e55a9612c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaem</th>\n",
              "      <th>ab</th>\n",
              "      <th>aback</th>\n",
              "      <th>abaft</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abandoning</th>\n",
              "      <th>abandonment</th>\n",
              "      <th>abaout</th>\n",
              "      <th>abashed</th>\n",
              "      <th>...</th>\n",
              "      <th>æmilianus</th>\n",
              "      <th>æneid</th>\n",
              "      <th>æronaut</th>\n",
              "      <th>æronauts</th>\n",
              "      <th>ærostation</th>\n",
              "      <th>æschylus</th>\n",
              "      <th>élite</th>\n",
              "      <th>émeutes</th>\n",
              "      <th>οἶδα</th>\n",
              "      <th>υπνος</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15658</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15659</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15660</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15661</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15662</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15663 rows × 23027 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aaem  ab  aback  abaft  abandon  abandoned  abandoning  abandonment  \\\n",
              "0         0   0      0      0        0          0           0            0   \n",
              "1         0   0      0      0        0          0           0            0   \n",
              "2         0   0      0      0        0          0           0            0   \n",
              "3         0   0      0      0        0          0           0            0   \n",
              "4         0   0      0      0        0          0           0            0   \n",
              "...     ...  ..    ...    ...      ...        ...         ...          ...   \n",
              "15658     0   0      0      0        0          0           0            0   \n",
              "15659     0   0      0      0        0          0           0            0   \n",
              "15660     0   0      0      0        0          0           0            0   \n",
              "15661     0   0      0      0        0          0           0            0   \n",
              "15662     0   0      0      0        0          0           0            0   \n",
              "\n",
              "       abaout  abashed  ...  æmilianus  æneid  æronaut  æronauts  ærostation  \\\n",
              "0           0        0  ...          0      0        0         0           0   \n",
              "1           0        0  ...          0      0        0         0           0   \n",
              "2           0        0  ...          0      0        0         0           0   \n",
              "3           0        0  ...          0      0        0         0           0   \n",
              "4           0        0  ...          0      0        0         0           0   \n",
              "...       ...      ...  ...        ...    ...      ...       ...         ...   \n",
              "15658       0        0  ...          0      0        0         0           0   \n",
              "15659       0        0  ...          0      0        0         0           0   \n",
              "15660       0        0  ...          0      0        0         0           0   \n",
              "15661       0        0  ...          0      0        0         0           0   \n",
              "15662       0        0  ...          0      0        0         0           0   \n",
              "\n",
              "       æschylus  élite  émeutes  οἶδα  υπνος  \n",
              "0             0      0        0     0      0  \n",
              "1             0      0        0     0      0  \n",
              "2             0      0        0     0      0  \n",
              "3             0      0        0     0      0  \n",
              "4             0      0        0     0      0  \n",
              "...         ...    ...      ...   ...    ...  \n",
              "15658         0      0        0     0      0  \n",
              "15659         0      0        0     0      0  \n",
              "15660         0      0        0     0      0  \n",
              "15661         0      0        0     0      0  \n",
              "15662         0      0        0     0      0  \n",
              "\n",
              "[15663 rows x 23027 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_array_cv = train_fl.toarray()\n",
        "df = pd.DataFrame(data=count_array_cv,columns = vectorizer.get_feature_names_out())\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "khiMXpG2o6b1",
        "outputId": "1d701f5f-a221-4dcb-c98e-c9552e596987"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaem</th>\n",
              "      <th>ab</th>\n",
              "      <th>aback</th>\n",
              "      <th>abaft</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abandoning</th>\n",
              "      <th>abandonment</th>\n",
              "      <th>abaout</th>\n",
              "      <th>abashed</th>\n",
              "      <th>...</th>\n",
              "      <th>æmilianus</th>\n",
              "      <th>æneid</th>\n",
              "      <th>æronaut</th>\n",
              "      <th>æronauts</th>\n",
              "      <th>ærostation</th>\n",
              "      <th>æschylus</th>\n",
              "      <th>élite</th>\n",
              "      <th>émeutes</th>\n",
              "      <th>οἶδα</th>\n",
              "      <th>υπνος</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15658</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15659</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15660</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15661</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15662</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15663 rows × 23027 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aaem  ab  aback  abaft  abandon  abandoned  abandoning  abandonment  \\\n",
              "0         0   0      0      0        0          0           0            0   \n",
              "1         0   0      0      0        0          0           0            0   \n",
              "2         0   0      0      0        0          0           0            0   \n",
              "3         0   0      0      0        0          0           0            0   \n",
              "4         0   0      0      0        0          0           0            0   \n",
              "...     ...  ..    ...    ...      ...        ...         ...          ...   \n",
              "15658     0   0      0      0        0          0           0            0   \n",
              "15659     0   0      0      0        0          0           0            0   \n",
              "15660     0   0      0      0        0          0           0            0   \n",
              "15661     0   0      0      0        0          0           0            0   \n",
              "15662     0   0      0      0        0          0           0            0   \n",
              "\n",
              "       abaout  abashed  ...  æmilianus  æneid  æronaut  æronauts  ærostation  \\\n",
              "0           0        0  ...          0      0        0         0           0   \n",
              "1           0        0  ...          0      0        0         0           0   \n",
              "2           0        0  ...          0      0        0         0           0   \n",
              "3           0        0  ...          0      0        0         0           0   \n",
              "4           0        0  ...          0      0        0         0           0   \n",
              "...       ...      ...  ...        ...    ...      ...       ...         ...   \n",
              "15658       0        0  ...          0      0        0         0           0   \n",
              "15659       0        0  ...          0      0        0         0           0   \n",
              "15660       0        0  ...          0      0        0         0           0   \n",
              "15661       0        0  ...          0      0        0         0           0   \n",
              "15662       0        0  ...          0      0        0         0           0   \n",
              "\n",
              "       æschylus  élite  émeutes  οἶδα  υπνος  \n",
              "0             0      0        0     0      0  \n",
              "1             0      0        0     0      0  \n",
              "2             0      0        0     0      0  \n",
              "3             0      0        0     0      0  \n",
              "4             0      0        0     0      0  \n",
              "...         ...    ...      ...   ...    ...  \n",
              "15658         0      0        0     0      0  \n",
              "15659         0      0        0     0      0  \n",
              "15660         0      0        0     0      0  \n",
              "15661         0      0        0     0      0  \n",
              "15662         0      0        0     0      0  \n",
              "\n",
              "[15663 rows x 23027 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_array_oneh = train_oneh.toarray()\n",
        "df = pd.DataFrame(data=count_array_oneh,columns = vectorizer_onehot.get_feature_names_out())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB_9OhDRo6b1"
      },
      "source": [
        "##### 2 et 3. Entrainer un modèle de vectorisation TF-IDF sur la partie d’entrainement et vectorisez-le. (et de test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4CZ6wBG2o6b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# création d'un objet TfidfVectorizer pour effectuer la vectorisation TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer= 'word', stop_words='english')\n",
        "\n",
        "# ajustement du vectorizer sur le texte d'entraînement\n",
        "tfidf_vectorizer.fit(X_train['text'])\n",
        "\n",
        "# transformation du texte d'entraînement et de test en vecteurs TF-IDF\n",
        "train_tfidf = tfidf_vectorizer.transform(X_train['text'])\n",
        "test_tfidf = tfidf_vectorizer.transform(X_test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EAQzv-I9o6b2",
        "outputId": "fcd306c6-7516-4679-bd05-08a38d0f16b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaem</th>\n",
              "      <th>ab</th>\n",
              "      <th>aback</th>\n",
              "      <th>abaft</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abandoning</th>\n",
              "      <th>abandonment</th>\n",
              "      <th>abaout</th>\n",
              "      <th>abashed</th>\n",
              "      <th>...</th>\n",
              "      <th>æmilianus</th>\n",
              "      <th>æneid</th>\n",
              "      <th>æronaut</th>\n",
              "      <th>æronauts</th>\n",
              "      <th>ærostation</th>\n",
              "      <th>æschylus</th>\n",
              "      <th>élite</th>\n",
              "      <th>émeutes</th>\n",
              "      <th>οἶδα</th>\n",
              "      <th>υπνος</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15658</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15659</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15660</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15661</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15662</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15663 rows × 23027 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aaem   ab  aback  abaft  abandon  abandoned  abandoning  abandonment  \\\n",
              "0       0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "1       0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "2       0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "3       0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "4       0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "...     ...  ...    ...    ...      ...        ...         ...          ...   \n",
              "15658   0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "15659   0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "15660   0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "15661   0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "15662   0.0  0.0    0.0    0.0      0.0        0.0         0.0          0.0   \n",
              "\n",
              "       abaout  abashed  ...  æmilianus  æneid  æronaut  æronauts  ærostation  \\\n",
              "0         0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "1         0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "2         0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "3         0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "4         0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "...       ...      ...  ...        ...    ...      ...       ...         ...   \n",
              "15658     0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "15659     0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "15660     0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "15661     0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "15662     0.0      0.0  ...        0.0    0.0      0.0       0.0         0.0   \n",
              "\n",
              "       æschylus  élite  émeutes  οἶδα  υπνος  \n",
              "0           0.0    0.0      0.0   0.0    0.0  \n",
              "1           0.0    0.0      0.0   0.0    0.0  \n",
              "2           0.0    0.0      0.0   0.0    0.0  \n",
              "3           0.0    0.0      0.0   0.0    0.0  \n",
              "4           0.0    0.0      0.0   0.0    0.0  \n",
              "...         ...    ...      ...   ...    ...  \n",
              "15658       0.0    0.0      0.0   0.0    0.0  \n",
              "15659       0.0    0.0      0.0   0.0    0.0  \n",
              "15660       0.0    0.0      0.0   0.0    0.0  \n",
              "15661       0.0    0.0      0.0   0.0    0.0  \n",
              "15662       0.0    0.0      0.0   0.0    0.0  \n",
              "\n",
              "[15663 rows x 23027 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_array_tfidf = train_tfidf.toarray()\n",
        "df = pd.DataFrame(data=count_array_tfidf,columns = tfidf_vectorizer.get_feature_names_out())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6dTvjudo6b2"
      },
      "source": [
        "Lexical frequency is a simple measure of how often a word appears in a document. It is calculated by dividing the number of occurrences of a word by the total number of words in the document.\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) is a more sophisticated measure that takes into account both the frequency of a word in a document and the frequency of the word in the entire corpus. It is calculated by multiplying the lexical frequency of a word by the inverse document frequency of the word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbCW3VGfo6b3"
      },
      "source": [
        "### E. Entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkZF-zw1o6b3"
      },
      "source": [
        "#### 1. Créer trois modèles du type MLPClassifier. (Vous pouvez changer l’algorithme d’apprentissage : utiliser les autres algorithmes de scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kZpfqpZOo6b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model1 = MLPClassifier(hidden_layer_sizes=(32,), activation='relu', solver='adam', random_state=1)\n",
        "model2 = MLPClassifier(hidden_layer_sizes=(16, 16), activation='relu', solver='adam', random_state=1)\n",
        "model3 = MLPClassifier(hidden_layer_sizes=(32, 16, 8), activation='relu', solver='adam', random_state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQhqNGpwo6b4"
      },
      "source": [
        "#### 2,3 et 4.\n",
        " - Entrainer ces trois modèles sur les trois représentations vectorielles\n",
        " - Prédire les classes en appliquant les trois modèles sur les trois représentations d’entrainement.\n",
        " - Afficher le rapport de classification en utilisant les mesures de performance (accuracy, precision, recall…).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLhKRZO4o6b5",
        "outputId": "cd2f419f-d58a-4a2f-d2cb-d61c7d5e9bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Model n˚1\n",
            "The model is training on the representation n˚1...\n",
            "✅Training completed within: 837.500425 seconds\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model is training on the representation n˚2...\n",
            "✅Training completed within: 758.312445 seconds\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model is training on the representation n˚3...\n",
            "✅Training completed within: 874.893491 seconds\n",
            "------------------------------------------------------------------\n",
            "MLP Model n˚2\n",
            "The model is training on the representation n˚1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 297.894916 seconds\n",
            "------------------------------------------------------------------\n",
            "The model is training on the representation n˚2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 255.538996 seconds\n",
            "------------------------------------------------------------------\n",
            "The model is training on the representation n˚3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 433.473668 seconds\n",
            "------------------------------------------------------------------\n",
            "MLP Model n˚3\n",
            "The model is training on the representation n˚1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 393.010804 seconds\n",
            "------------------------------------------------------------------\n",
            "The model is training on the representation n˚2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 376.417279 seconds\n",
            "------------------------------------------------------------------\n",
            "The model is training on the representation n˚3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅Training completed within: 321.259453 seconds\n",
            "------------------------------------------------------------------\n",
            "Training completed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle, os\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "import warnings\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "import time\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "representations = [train_fl, train_oneh, train_tfidf]\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"MLP Model n˚{i + 1}\")\n",
        "    for j, representation in enumerate(representations):\n",
        "\n",
        "        print(f\"The model is training on the representation n˚{j + 1}...\")\n",
        "        start_time = time.time()\n",
        "        model.fit(representation, y_train)\n",
        "        end_time = time.time()\n",
        "        print(f\"✅Training completed within: {end_time - start_time:.6f} seconds\")\n",
        "        print(f\"------------------------------------------------------------------\")\n",
        "        filename = f'models/model{i+1}.{j+1}.sav'\n",
        "        pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "        y_pred = model.predict(representation)\n",
        "\n",
        "        report = classification_report(y_train, y_pred, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "        report_df.to_csv(f\"metrics/model{i+1}.{j+1}.csv\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = []\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        filename = f'metrics/model{i+1}.{j+1}.csv'\n",
        "        df = pd.read_csv(filename, index_col=0)\n",
        "        metrics.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999525</td>\n",
              "      <td>0.998259</td>\n",
              "      <td>0.998892</td>\n",
              "      <td>6320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.999556</td>\n",
              "      <td>0.999113</td>\n",
              "      <td>0.999334</td>\n",
              "      <td>4508.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.999793</td>\n",
              "      <td>0.997104</td>\n",
              "      <td>0.998447</td>\n",
              "      <td>4835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro avg</th>\n",
              "      <td>0.999616</td>\n",
              "      <td>0.998149</td>\n",
              "      <td>0.998882</td>\n",
              "      <td>15663.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.999624</td>\n",
              "      <td>0.998159</td>\n",
              "      <td>0.998891</td>\n",
              "      <td>15663.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.999616</td>\n",
              "      <td>0.998149</td>\n",
              "      <td>0.998882</td>\n",
              "      <td>15663.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>samples avg</th>\n",
              "      <td>0.998117</td>\n",
              "      <td>0.998149</td>\n",
              "      <td>0.998127</td>\n",
              "      <td>15663.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score  support\n",
              "0              0.999525  0.998259  0.998892   6320.0\n",
              "1              0.999556  0.999113  0.999334   4508.0\n",
              "2              0.999793  0.997104  0.998447   4835.0\n",
              "micro avg      0.999616  0.998149  0.998882  15663.0\n",
              "macro avg      0.999624  0.998159  0.998891  15663.0\n",
              "weighted avg   0.999616  0.998149  0.998882  15663.0\n",
              "samples avg    0.998117  0.998149  0.998127  15663.0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9j8g4Hyo6b5"
      },
      "source": [
        "### F. Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7fYUfrDo6b6"
      },
      "source": [
        "##### Pour Model i et La Representation 1 (CountVect ) et 2 (one hot) et 3 (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfeaUepCo6b7",
        "outputId": "adbf494a-7407-46d9-c3ea-ac7f25863f56"
      },
      "outputs": [],
      "source": [
        "models = [model1, model2, model3]\n",
        "test_representations = [test_fl, test_oneh, test_tfidf]\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    for j, representation in enumerate(test_representations):\n",
        "\n",
        "        filename = f\"models/model{i+1}.{j+1}.sav\"\n",
        "        model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "        y_pred = model.predict(representation)\n",
        "\n",
        "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "        report_df.to_csv(f\"metrics/test_model{i+1}.{j+1}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = []\n",
        "for i in range(len(models)):\n",
        "    for j in range(len(test_representations)):\n",
        "        filename = f'metrics/test_model{i+1}.{j+1}.csv'\n",
        "        df = pd.read_csv(filename, index_col=0)\n",
        "        metrics.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.729244</td>\n",
              "      <td>0.744937</td>\n",
              "      <td>0.737007</td>\n",
              "      <td>1580.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.745301</td>\n",
              "      <td>0.703638</td>\n",
              "      <td>0.723870</td>\n",
              "      <td>1127.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.698401</td>\n",
              "      <td>0.758478</td>\n",
              "      <td>0.727201</td>\n",
              "      <td>1209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro avg</th>\n",
              "      <td>0.723378</td>\n",
              "      <td>0.737232</td>\n",
              "      <td>0.730239</td>\n",
              "      <td>3916.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.724315</td>\n",
              "      <td>0.735684</td>\n",
              "      <td>0.729359</td>\n",
              "      <td>3916.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.724343</td>\n",
              "      <td>0.737232</td>\n",
              "      <td>0.730199</td>\n",
              "      <td>3916.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>samples avg</th>\n",
              "      <td>0.709270</td>\n",
              "      <td>0.737232</td>\n",
              "      <td>0.718590</td>\n",
              "      <td>3916.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score  support\n",
              "0              0.729244  0.744937  0.737007   1580.0\n",
              "1              0.745301  0.703638  0.723870   1127.0\n",
              "2              0.698401  0.758478  0.727201   1209.0\n",
              "micro avg      0.723378  0.737232  0.730239   3916.0\n",
              "macro avg      0.724315  0.735684  0.729359   3916.0\n",
              "weighted avg   0.724343  0.737232  0.730199   3916.0\n",
              "samples avg    0.709270  0.737232  0.718590   3916.0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuScQ75Do6b7"
      },
      "source": [
        "### G. Vectorisations basées sur les embeddings de mots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuVrHcXAo6b8"
      },
      "source": [
        "#### a. Word2Vec (CBOW and Skip gram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzvfYty58Ixj"
      },
      "source": [
        "#### Tokenization function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "la = LabelEncoder()\n",
        "data['author_encoded'] = la.fit_transform(data['author'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'].values,\n",
        "                                                    data['author_encoded'].values,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=33,\n",
        "                                                    stratify = data['author_encoded'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CPS8ed6to6b-"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "train_tokens = [tokenize(text) for text in X_train]\n",
        "test_tokens = [tokenize(text) for text in X_test]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCXQyQ3h8KY7"
      },
      "source": [
        "#### Mean vector function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tBrzC_-eo6b-"
      },
      "outputs": [],
      "source": [
        "def get_mean_vector(vectors, words):\n",
        "    words = [word for word in words if word in vectors]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(vectors[words], axis=0)\n",
        "    else:\n",
        "        return np.zeros(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ti6dw6R8Si7"
      },
      "source": [
        "#### Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "M6u1FMLdo6b_"
      },
      "outputs": [],
      "source": [
        "# Skip-Gram\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import FastText, KeyedVectors\n",
        "model_sg = Word2Vec(train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
        "\n",
        "train_sg = [get_mean_vector(model_sg.wv, words) for words in train_tokens]\n",
        "test_sg = [get_mean_vector(model_sg.wv, words) for words in test_tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c48K4WUv8Z96"
      },
      "source": [
        "CBOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hmM7BsJ1o6cA"
      },
      "outputs": [],
      "source": [
        "# CBOW\n",
        "model_cbow = Word2Vec(train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
        "\n",
        "train_cbow = [get_mean_vector(model_cbow.wv, words) for words in train_tokens]\n",
        "test_cbow = [get_mean_vector(model_cbow.wv, words) for words in test_tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MyfHW6A8eJZ"
      },
      "source": [
        "The difference between Skip-Gram and CBOW is on parameter sg = 0 on CBOW and sg = 1 on Skip-Gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "binkOZPM81d7"
      },
      "source": [
        "#### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "4YhPb7ob8sTj",
        "outputId": "b1805636-9bd5-4da3-a5ae-bb03d67aee48"
      },
      "outputs": [],
      "source": [
        "model_glove = KeyedVectors.load_word2vec_format('glove.6B.100d.txt', binary=False, no_header=True)\n",
        "\n",
        "train_glove = [get_mean_vector(model_glove, words) for words in train_tokens]\n",
        "test_glove = [get_mean_vector(model_glove, words) for words in test_tokens]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### FAST TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model_fasttext = FastText(train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "train_fasttext = [get_mean_vector(model_fasttext.wv, words) for words in train_tokens]\n",
        "test_fasttext = [get_mean_vector(model_fasttext.wv, words) for words in test_tokens]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training / Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LjmMXv1n9Jer"
      },
      "outputs": [],
      "source": [
        "models = [model1, model2, model3]\n",
        "representations = [train_sg, train_cbow, train_glove, train_fasttext]\n",
        "test_representations = [test_sg, test_cbow, test_glove, test_fasttext]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_all(models, representation, y_train):\n",
        "    for i, model in enumerate(models):\n",
        "        print(f\"MLP Model n˚{i + 1}\")\n",
        "        for j, representation in enumerate(representations):\n",
        "    \n",
        "            print(f\" • The model is training on the representation n˚{j + 1}...\")\n",
        "            start_time = time.time()\n",
        "            \n",
        "            print(y_train.shape)\n",
        "            model.fit(representation, y_train)\n",
        "            end_time = time.time()\n",
        "            print(f\"✔️ Training completed within: {end_time - start_time:.6f} seconds\")\n",
        "            print(f\"------------------------------------------------------------------\")\n",
        "            filename = f'models/finalized_model{i+1}.{j+1}.sav'\n",
        "            pickle.dump(model, open(filename, 'wb'))\n",
        "    \n",
        "            y_pred = model.predict(representation)\n",
        "    \n",
        "            report = classification_report(y_train, y_pred, output_dict=True, zero_division=0)\n",
        "            report_df = pd.DataFrame(report).transpose()\n",
        "    \n",
        "            report_df.to_csv(f\"metrics/model{i+1}.{j+1}.csv\")\n",
        "    print(\"✅ Training completed!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Applying the models on the train representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Model n˚1\n",
            " • The model is training on the representation n˚1...\n",
            "(15663,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ Training completed within: 30.429313 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚2...\n",
            "(15663,)\n",
            "✔️ Training completed within: 12.411395 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚3...\n",
            "(15663,)\n",
            "✔️ Training completed within: 8.442138 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚4...\n",
            "(15663,)\n",
            "✔️ Training completed within: 18.354839 seconds\n",
            "------------------------------------------------------------------\n",
            "MLP Model n˚2\n",
            " • The model is training on the representation n˚1...\n",
            "(15663,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ Training completed within: 30.949103 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚2...\n",
            "(15663,)\n",
            "✔️ Training completed within: 20.413685 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚3...\n",
            "(15663,)\n",
            "✔️ Training completed within: 7.769463 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚4...\n",
            "(15663,)\n",
            "✔️ Training completed within: 13.925026 seconds\n",
            "------------------------------------------------------------------\n",
            "MLP Model n˚3\n",
            " • The model is training on the representation n˚1...\n",
            "(15663,)\n",
            "✔️ Training completed within: 36.327971 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚2...\n",
            "(15663,)\n",
            "✔️ Training completed within: 14.489486 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚3...\n",
            "(15663,)\n",
            "✔️ Training completed within: 9.949527 seconds\n",
            "------------------------------------------------------------------\n",
            " • The model is training on the representation n˚4...\n",
            "(15663,)\n",
            "✔️ Training completed within: 15.578091 seconds\n",
            "------------------------------------------------------------------\n",
            "✅ Training completed!\n"
          ]
        }
      ],
      "source": [
        "#### Applying the models on the train representations\n",
        "train_all(models, representations, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Applying the models on the train representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, model in enumerate(models):\n",
        "    for j, representation in enumerate(test_representations):\n",
        "\n",
        "        filename = f\"models/finalized_model{i+1}.{j+1}.sav\"\n",
        "        model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "        y_pred = model.predict(representation)\n",
        "\n",
        "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "        report_df.to_csv(f\"metrics/test_model{i+1}.{j+1}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1-Score'])\n",
        "models_names = ['MLP-32_CV', 'MLP-32_OneHot', 'MLP-32_TFIDF', 'MLP-16-16_CV', 'MLP-16-16_OneHot', 'MLP-16-16_TFIDF', 'MLP-32-16-8_CV', 'MLP-32-16-8_OneHot', 'MLP-32-16-8_TFIDF']\n",
        "k = 0\n",
        "for i in range(3):\n",
        "    model_name = f\"Model {i+1}\"\n",
        "    \n",
        "    for j in range(3):\n",
        "        filename = f'metrics/test_model{i+1}.{j+1}.csv'\n",
        "        df = pd.read_csv(filename, index_col=0)\n",
        "        \n",
        "        accuracy = df.loc['accuracy', 'precision']\n",
        "        recall = df.loc['macro avg', 'recall']\n",
        "        precision = df.loc['macro avg', 'precision']\n",
        "        f1_score = df.loc['macro avg', 'f1-score']\n",
        "        \n",
        "        metrics_df.loc[k] = [models_names[k], accuracy, recall, precision, f1_score]\n",
        "        k += 1\n",
        "    \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLP-32_CV</td>\n",
              "      <td>0.589888</td>\n",
              "      <td>0.579646</td>\n",
              "      <td>0.586748</td>\n",
              "      <td>0.581840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MLP-32_OneHot</td>\n",
              "      <td>0.401685</td>\n",
              "      <td>0.362245</td>\n",
              "      <td>0.378498</td>\n",
              "      <td>0.308376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MLP-32_TFIDF</td>\n",
              "      <td>0.395812</td>\n",
              "      <td>0.352275</td>\n",
              "      <td>0.249767</td>\n",
              "      <td>0.279738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP-16-16_CV</td>\n",
              "      <td>0.581716</td>\n",
              "      <td>0.552720</td>\n",
              "      <td>0.626167</td>\n",
              "      <td>0.548976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MLP-16-16_OneHot</td>\n",
              "      <td>0.395046</td>\n",
              "      <td>0.339745</td>\n",
              "      <td>0.393382</td>\n",
              "      <td>0.262682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MLP-16-16_TFIDF</td>\n",
              "      <td>0.400919</td>\n",
              "      <td>0.370995</td>\n",
              "      <td>0.258887</td>\n",
              "      <td>0.303283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MLP-32-16-8_CV</td>\n",
              "      <td>0.602400</td>\n",
              "      <td>0.592930</td>\n",
              "      <td>0.600661</td>\n",
              "      <td>0.595293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MLP-32-16-8_OneHot</td>\n",
              "      <td>0.408836</td>\n",
              "      <td>0.360943</td>\n",
              "      <td>0.408773</td>\n",
              "      <td>0.286244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MLP-32-16-8_TFIDF</td>\n",
              "      <td>0.400664</td>\n",
              "      <td>0.370529</td>\n",
              "      <td>0.258679</td>\n",
              "      <td>0.302870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model  Accuracy    Recall  Precision  F1-Score\n",
              "0           MLP-32_CV  0.589888  0.579646   0.586748  0.581840\n",
              "1       MLP-32_OneHot  0.401685  0.362245   0.378498  0.308376\n",
              "2        MLP-32_TFIDF  0.395812  0.352275   0.249767  0.279738\n",
              "3        MLP-16-16_CV  0.581716  0.552720   0.626167  0.548976\n",
              "4    MLP-16-16_OneHot  0.395046  0.339745   0.393382  0.262682\n",
              "5     MLP-16-16_TFIDF  0.400919  0.370995   0.258887  0.303283\n",
              "6      MLP-32-16-8_CV  0.602400  0.592930   0.600661  0.595293\n",
              "7  MLP-32-16-8_OneHot  0.408836  0.360943   0.408773  0.286244\n",
              "8   MLP-32-16-8_TFIDF  0.400664  0.370529   0.258679  0.302870"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training CBOW or Skip Gram from scratch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### skip-gram model from scratch using PyTorch to build and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/59/1f/4975d1ab3ed2244053876321ef65bc02935daed67da76c6e7d65900772a3/torch-2.2.1-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading torch-2.2.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
            "Collecting torchvision\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/e7/45/419aa0b37254f1fd62b45bb63836066c5eb81e37d70940e0491e95167eed/torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torch-2.2.1-cp311-cp311-win_amd64.whl (198.6 MB)\n",
            "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/198.6 MB 656.4 kB/s eta 0:05:03\n",
            "   ---------------------------------------- 0.1/198.6 MB 939.4 kB/s eta 0:03:32\n",
            "   ---------------------------------------- 0.2/198.6 MB 1.1 MB/s eta 0:02:56\n",
            "   ---------------------------------------- 0.4/198.6 MB 1.8 MB/s eta 0:01:49\n",
            "   ---------------------------------------- 0.7/198.6 MB 2.7 MB/s eta 0:01:14\n",
            "   ---------------------------------------- 1.0/198.6 MB 3.1 MB/s eta 0:01:05\n",
            "   ---------------------------------------- 1.3/198.6 MB 3.7 MB/s eta 0:00:54\n",
            "   ---------------------------------------- 1.7/198.6 MB 4.1 MB/s eta 0:00:48\n",
            "   ---------------------------------------- 2.0/198.6 MB 4.5 MB/s eta 0:00:45\n",
            "   ---------------------------------------- 2.4/198.6 MB 4.8 MB/s eta 0:00:42\n",
            "    --------------------------------------- 2.7/198.6 MB 4.8 MB/s eta 0:00:41\n",
            "    --------------------------------------- 3.0/198.6 MB 5.1 MB/s eta 0:00:39\n",
            "    --------------------------------------- 3.3/198.6 MB 5.1 MB/s eta 0:00:39\n",
            "    --------------------------------------- 3.6/198.6 MB 5.2 MB/s eta 0:00:38\n",
            "    --------------------------------------- 4.0/198.6 MB 5.4 MB/s eta 0:00:37\n",
            "    --------------------------------------- 4.3/198.6 MB 5.4 MB/s eta 0:00:36\n",
            "    --------------------------------------- 4.7/198.6 MB 5.5 MB/s eta 0:00:36\n",
            "   - -------------------------------------- 5.0/198.6 MB 5.7 MB/s eta 0:00:35\n",
            "   - -------------------------------------- 5.3/198.6 MB 5.7 MB/s eta 0:00:35\n",
            "   - -------------------------------------- 5.7/198.6 MB 5.8 MB/s eta 0:00:34\n",
            "   - -------------------------------------- 6.0/198.6 MB 5.8 MB/s eta 0:00:34\n",
            "   - -------------------------------------- 6.3/198.6 MB 5.8 MB/s eta 0:00:33\n",
            "   - -------------------------------------- 6.6/198.6 MB 5.8 MB/s eta 0:00:33\n",
            "   - -------------------------------------- 7.0/198.6 MB 5.9 MB/s eta 0:00:33\n",
            "   - -------------------------------------- 7.3/198.6 MB 6.0 MB/s eta 0:00:32\n",
            "   - -------------------------------------- 7.7/198.6 MB 6.1 MB/s eta 0:00:32\n",
            "   - -------------------------------------- 8.0/198.6 MB 6.1 MB/s eta 0:00:32\n",
            "   - -------------------------------------- 8.4/198.6 MB 6.2 MB/s eta 0:00:31\n",
            "   - -------------------------------------- 8.7/198.6 MB 6.2 MB/s eta 0:00:31\n",
            "   - -------------------------------------- 9.1/198.6 MB 6.2 MB/s eta 0:00:31\n",
            "   - -------------------------------------- 9.4/198.6 MB 6.3 MB/s eta 0:00:31\n",
            "   - -------------------------------------- 9.7/198.6 MB 6.3 MB/s eta 0:00:31\n",
            "   -- ------------------------------------- 10.1/198.6 MB 6.3 MB/s eta 0:00:30\n",
            "   -- ------------------------------------- 10.4/198.6 MB 6.9 MB/s eta 0:00:28\n",
            "   -- ------------------------------------- 10.8/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 11.1/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 11.5/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 11.8/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 12.2/198.6 MB 7.1 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 12.5/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 12.9/198.6 MB 7.1 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 13.2/198.6 MB 7.1 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 13.5/198.6 MB 7.1 MB/s eta 0:00:26\n",
            "   -- ------------------------------------- 13.7/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 14.0/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 14.3/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 14.3/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 14.3/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   -- ------------------------------------- 14.4/198.6 MB 6.4 MB/s eta 0:00:29\n",
            "   --- ------------------------------------ 15.0/198.6 MB 6.5 MB/s eta 0:00:29\n",
            "   --- ------------------------------------ 15.9/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 16.3/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 16.6/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 17.0/198.6 MB 7.0 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 17.2/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 17.6/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   --- ------------------------------------ 17.9/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 18.3/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 18.6/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 19.0/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 19.3/198.6 MB 6.9 MB/s eta 0:00:27\n",
            "   --- ------------------------------------ 19.7/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 20.0/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 20.4/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 20.8/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 20.9/198.6 MB 6.9 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 21.2/198.6 MB 6.8 MB/s eta 0:00:27\n",
            "   ---- ----------------------------------- 21.6/198.6 MB 6.8 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 22.0/198.6 MB 6.8 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 22.3/198.6 MB 6.9 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 22.7/198.6 MB 6.8 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 23.0/198.6 MB 6.8 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 23.3/198.6 MB 6.9 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 23.7/198.6 MB 6.9 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 24.0/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 24.4/198.6 MB 7.0 MB/s eta 0:00:26\n",
            "   ---- ----------------------------------- 24.7/198.6 MB 7.7 MB/s eta 0:00:23\n",
            "   ----- ---------------------------------- 25.1/198.6 MB 7.6 MB/s eta 0:00:23\n",
            "   ----- ---------------------------------- 25.4/198.6 MB 7.4 MB/s eta 0:00:24\n",
            "   ----- ---------------------------------- 25.8/198.6 MB 7.3 MB/s eta 0:00:24\n",
            "   ----- ---------------------------------- 26.1/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 26.4/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 26.7/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 27.1/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 27.4/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 27.8/198.6 MB 7.1 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 28.2/198.6 MB 7.2 MB/s eta 0:00:24\n",
            "   ----- ---------------------------------- 28.5/198.6 MB 7.0 MB/s eta 0:00:25\n",
            "   ----- ---------------------------------- 28.9/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ----- ---------------------------------- 29.2/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ----- ---------------------------------- 29.6/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 29.9/198.6 MB 7.2 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 30.2/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 30.6/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 30.9/198.6 MB 7.1 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 31.3/198.6 MB 7.2 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 31.6/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 32.0/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 32.3/198.6 MB 7.2 MB/s eta 0:00:24\n",
            "   ------ --------------------------------- 32.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 33.0/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 33.4/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 33.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 34.1/198.6 MB 7.4 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 34.4/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 34.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 35.1/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 35.4/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 35.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 36.1/198.6 MB 7.2 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 36.4/198.6 MB 7.2 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 36.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 36.9/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 37.3/198.6 MB 7.1 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 37.6/198.6 MB 7.1 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 37.9/198.6 MB 7.1 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 38.2/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 38.6/198.6 MB 7.1 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 38.9/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 39.2/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   ------- -------------------------------- 39.6/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 39.9/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 40.3/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 40.6/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 40.9/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 41.3/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 41.6/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 42.0/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 42.3/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 42.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.0/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.4/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 43.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 44.0/198.6 MB 6.3 MB/s eta 0:00:25\n",
            "   --------- ------------------------------ 45.4/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 45.7/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 46.0/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 46.3/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 46.7/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 47.0/198.6 MB 7.1 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 47.4/198.6 MB 7.1 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 47.7/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 48.0/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 48.4/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 48.8/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 49.1/198.6 MB 7.0 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 49.4/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 49.8/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 50.2/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 50.5/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 50.8/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 51.2/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 51.5/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 51.9/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 52.3/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 52.6/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 52.9/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 53.3/198.6 MB 7.2 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 53.7/198.6 MB 7.1 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 54.0/198.6 MB 8.1 MB/s eta 0:00:18\n",
            "   ---------- ----------------------------- 54.4/198.6 MB 8.0 MB/s eta 0:00:19\n",
            "   ----------- ---------------------------- 54.7/198.6 MB 7.7 MB/s eta 0:00:19\n",
            "   ----------- ---------------------------- 55.1/198.6 MB 7.5 MB/s eta 0:00:20\n",
            "   ----------- ---------------------------- 55.3/198.6 MB 7.3 MB/s eta 0:00:20\n",
            "   ----------- ---------------------------- 55.5/198.6 MB 7.2 MB/s eta 0:00:20\n",
            "   ----------- ---------------------------- 55.6/198.6 MB 7.0 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 55.8/198.6 MB 6.8 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 56.1/198.6 MB 6.8 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 56.5/198.6 MB 6.9 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 56.7/198.6 MB 6.8 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 56.9/198.6 MB 6.7 MB/s eta 0:00:22\n",
            "   ----------- ---------------------------- 57.2/198.6 MB 6.7 MB/s eta 0:00:22\n",
            "   ----------- ---------------------------- 57.6/198.6 MB 6.7 MB/s eta 0:00:22\n",
            "   ----------- ---------------------------- 58.0/198.6 MB 6.7 MB/s eta 0:00:22\n",
            "   ----------- ---------------------------- 58.3/198.6 MB 6.7 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 58.3/198.6 MB 6.7 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 58.3/198.6 MB 6.7 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 58.3/198.6 MB 6.7 MB/s eta 0:00:21\n",
            "   ----------- ---------------------------- 58.6/198.6 MB 6.1 MB/s eta 0:00:23\n",
            "   ----------- ---------------------------- 58.6/198.6 MB 6.1 MB/s eta 0:00:23\n",
            "   ----------- ---------------------------- 58.8/198.6 MB 6.0 MB/s eta 0:00:24\n",
            "   ----------- ---------------------------- 58.8/198.6 MB 6.0 MB/s eta 0:00:24\n",
            "   ----------- ---------------------------- 58.9/198.6 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 59.1/198.6 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 59.1/198.6 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 59.2/198.6 MB 5.3 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 59.6/198.6 MB 5.3 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 59.7/198.6 MB 5.3 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 59.7/198.6 MB 5.3 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 60.5/198.6 MB 5.2 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 60.9/198.6 MB 5.3 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 61.1/198.6 MB 5.2 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 61.5/198.6 MB 5.3 MB/s eta 0:00:26\n",
            "   ------------ --------------------------- 61.8/198.6 MB 5.2 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 61.9/198.6 MB 5.1 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 62.1/198.6 MB 5.1 MB/s eta 0:00:27\n",
            "   ------------ --------------------------- 62.3/198.6 MB 5.0 MB/s eta 0:00:28\n",
            "   ------------ --------------------------- 62.4/198.6 MB 4.9 MB/s eta 0:00:28\n",
            "   ------------ --------------------------- 62.6/198.6 MB 4.9 MB/s eta 0:00:28\n",
            "   ------------ --------------------------- 62.8/198.6 MB 4.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 62.8/198.6 MB 4.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 62.9/198.6 MB 4.7 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 62.9/198.6 MB 4.6 MB/s eta 0:00:30\n",
            "   ------------ --------------------------- 63.2/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------ --------------------------- 63.4/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------ --------------------------- 63.6/198.6 MB 4.5 MB/s eta 0:00:31\n",
            "   ------------ --------------------------- 63.7/198.6 MB 4.4 MB/s eta 0:00:31\n",
            "   ------------ --------------------------- 63.9/198.6 MB 4.4 MB/s eta 0:00:31\n",
            "   ------------ --------------------------- 64.2/198.6 MB 4.4 MB/s eta 0:00:31\n",
            "   ------------ --------------------------- 64.5/198.6 MB 4.3 MB/s eta 0:00:31\n",
            "   ------------- -------------------------- 64.7/198.6 MB 4.3 MB/s eta 0:00:31\n",
            "   ------------- -------------------------- 64.9/198.6 MB 4.3 MB/s eta 0:00:32\n",
            "   ------------- -------------------------- 65.3/198.6 MB 4.3 MB/s eta 0:00:32\n",
            "   ------------- -------------------------- 65.7/198.6 MB 4.3 MB/s eta 0:00:31\n",
            "   ------------- -------------------------- 66.0/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 66.3/198.6 MB 4.4 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 66.7/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 67.0/198.6 MB 4.5 MB/s eta 0:00:29\n",
            "   ------------- -------------------------- 67.3/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 67.7/198.6 MB 4.5 MB/s eta 0:00:29\n",
            "   ------------- -------------------------- 68.0/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 68.4/198.6 MB 4.5 MB/s eta 0:00:30\n",
            "   ------------- -------------------------- 68.7/198.6 MB 4.8 MB/s eta 0:00:27\n",
            "   ------------- -------------------------- 69.1/198.6 MB 5.2 MB/s eta 0:00:25\n",
            "   ------------- -------------------------- 69.2/198.6 MB 5.2 MB/s eta 0:00:25\n",
            "   ------------- -------------------------- 69.3/198.6 MB 5.0 MB/s eta 0:00:26\n",
            "   ------------- -------------------------- 69.3/198.6 MB 4.9 MB/s eta 0:00:27\n",
            "   ------------- -------------------------- 69.5/198.6 MB 5.1 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 69.7/198.6 MB 5.1 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 69.7/198.6 MB 5.0 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 70.0/198.6 MB 5.2 MB/s eta 0:00:25\n",
            "   -------------- ------------------------- 70.1/198.6 MB 5.1 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 70.4/198.6 MB 4.9 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 70.6/198.6 MB 4.8 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 70.9/198.6 MB 4.8 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 71.3/198.6 MB 4.8 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 71.6/198.6 MB 4.9 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 71.9/198.6 MB 4.9 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 72.2/198.6 MB 4.9 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 72.5/198.6 MB 5.0 MB/s eta 0:00:26\n",
            "   -------------- ------------------------- 72.8/198.6 MB 5.1 MB/s eta 0:00:25\n",
            "   -------------- ------------------------- 73.1/198.6 MB 5.4 MB/s eta 0:00:24\n",
            "   -------------- ------------------------- 73.4/198.6 MB 5.5 MB/s eta 0:00:23\n",
            "   -------------- ------------------------- 73.7/198.6 MB 5.6 MB/s eta 0:00:23\n",
            "   -------------- ------------------------- 74.0/198.6 MB 5.8 MB/s eta 0:00:22\n",
            "   -------------- ------------------------- 74.4/198.6 MB 5.7 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 74.7/198.6 MB 5.7 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 75.0/198.6 MB 5.8 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 75.2/198.6 MB 5.9 MB/s eta 0:00:21\n",
            "   --------------- ------------------------ 75.4/198.6 MB 5.7 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 75.7/198.6 MB 5.7 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 75.9/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 76.3/198.6 MB 5.7 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 76.5/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 76.8/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 77.1/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 77.5/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 77.8/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 78.1/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 78.4/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 78.8/198.6 MB 5.5 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 79.1/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   --------------- ------------------------ 79.4/198.6 MB 5.6 MB/s eta 0:00:22\n",
            "   ---------------- ----------------------- 79.7/198.6 MB 6.0 MB/s eta 0:00:20\n",
            "   ---------------- ----------------------- 80.0/198.6 MB 6.2 MB/s eta 0:00:20\n",
            "   ---------------- ----------------------- 80.4/198.6 MB 6.3 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 80.7/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 81.0/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 81.3/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 81.6/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 81.9/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 82.2/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 82.5/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 82.9/198.6 MB 6.4 MB/s eta 0:00:19\n",
            "   ---------------- ----------------------- 83.2/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ---------------- ----------------------- 83.5/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ---------------- ----------------------- 83.8/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ---------------- ----------------------- 84.1/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 84.4/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 84.7/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 85.1/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 85.3/198.6 MB 6.4 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 85.7/198.6 MB 6.5 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 86.0/198.6 MB 6.5 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 86.3/198.6 MB 6.5 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 86.6/198.6 MB 6.5 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 86.9/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 87.2/198.6 MB 6.5 MB/s eta 0:00:18\n",
            "   ----------------- ---------------------- 87.5/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 87.9/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 88.2/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 88.5/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 88.8/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 89.2/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ------------------ --------------------- 89.5/198.6 MB 6.6 MB/s eta 0:00:17\n",
            "   ------------------ --------------------- 89.6/198.6 MB 6.5 MB/s eta 0:00:17\n",
            "   ------------------ --------------------- 89.7/198.6 MB 6.4 MB/s eta 0:00:17\n",
            "   ------------------ --------------------- 89.7/198.6 MB 6.2 MB/s eta 0:00:18\n",
            "   ------------------ --------------------- 89.8/198.6 MB 6.0 MB/s eta 0:00:19\n",
            "   ------------------ --------------------- 89.8/198.6 MB 5.9 MB/s eta 0:00:19\n",
            "   ------------------ --------------------- 89.9/198.6 MB 5.7 MB/s eta 0:00:19\n",
            "   ------------------ --------------------- 90.1/198.6 MB 5.7 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 90.2/198.6 MB 5.6 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 90.3/198.6 MB 5.6 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 90.6/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 90.6/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 91.0/198.6 MB 5.4 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 91.4/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 91.7/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 92.0/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 92.3/198.6 MB 5.5 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 92.5/198.6 MB 5.4 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 92.6/198.6 MB 5.3 MB/s eta 0:00:21\n",
            "   ------------------ --------------------- 92.9/198.6 MB 5.3 MB/s eta 0:00:21\n",
            "   ------------------ --------------------- 93.2/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 93.6/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 93.9/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------ --------------------- 94.2/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 94.5/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 94.8/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 95.1/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 95.4/198.6 MB 5.2 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 95.7/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 96.0/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 96.3/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 96.6/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 96.9/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 97.2/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 97.5/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 97.9/198.6 MB 5.2 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 98.1/198.6 MB 5.3 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 98.5/198.6 MB 5.3 MB/s eta 0:00:19\n",
            "   ------------------- -------------------- 98.7/198.6 MB 5.2 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 98.8/198.6 MB 5.1 MB/s eta 0:00:20\n",
            "   ------------------- -------------------- 99.1/198.6 MB 5.1 MB/s eta 0:00:20\n",
            "   -------------------- ------------------- 99.5/198.6 MB 5.1 MB/s eta 0:00:20\n",
            "   -------------------- ------------------- 99.8/198.6 MB 5.1 MB/s eta 0:00:20\n",
            "   -------------------- ------------------- 100.1/198.6 MB 5.8 MB/s eta 0:00:17\n",
            "   -------------------- ------------------- 100.4/198.6 MB 6.0 MB/s eta 0:00:17\n",
            "   -------------------- ------------------- 100.8/198.6 MB 6.1 MB/s eta 0:00:17\n",
            "   -------------------- ------------------- 101.1/198.6 MB 6.3 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 101.3/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 101.6/198.6 MB 6.1 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 101.8/198.6 MB 6.1 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 102.2/198.6 MB 6.1 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 102.5/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 102.8/198.6 MB 6.3 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 103.1/198.6 MB 6.3 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 103.4/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 103.7/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   -------------------- ------------------- 104.0/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 104.3/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 104.6/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 104.9/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 105.2/198.6 MB 6.3 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 105.5/198.6 MB 6.3 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 105.7/198.6 MB 6.2 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 106.0/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 106.3/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 106.6/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 106.9/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 107.2/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 107.4/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 107.4/198.6 MB 6.2 MB/s eta 0:00:15\n",
            "   --------------------- ------------------ 107.6/198.6 MB 5.7 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 107.7/198.6 MB 5.7 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 107.7/198.6 MB 5.7 MB/s eta 0:00:16\n",
            "   --------------------- ------------------ 107.7/198.6 MB 5.4 MB/s eta 0:00:17\n",
            "   --------------------- ------------------ 108.0/198.6 MB 5.4 MB/s eta 0:00:17\n",
            "   --------------------- ------------------ 108.2/198.6 MB 5.3 MB/s eta 0:00:18\n",
            "   --------------------- ------------------ 108.5/198.6 MB 5.3 MB/s eta 0:00:18\n",
            "   --------------------- ------------------ 108.8/198.6 MB 5.2 MB/s eta 0:00:18\n",
            "   --------------------- ------------------ 109.0/198.6 MB 5.2 MB/s eta 0:00:18\n",
            "   --------------------- ------------------ 109.2/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 109.3/198.6 MB 5.2 MB/s eta 0:00:18\n",
            "   ---------------------- ----------------- 109.6/198.6 MB 5.2 MB/s eta 0:00:18\n",
            "   ---------------------- ----------------- 109.9/198.6 MB 5.2 MB/s eta 0:00:18\n",
            "   ---------------------- ----------------- 110.3/198.6 MB 5.2 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 110.6/198.6 MB 5.2 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 110.9/198.6 MB 5.2 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 111.2/198.6 MB 5.2 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 111.5/198.6 MB 5.2 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 111.9/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 112.2/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 112.5/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 112.8/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 113.1/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 113.4/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ---------------------- ----------------- 113.8/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ---------------------- ----------------- 114.1/198.6 MB 5.3 MB/s eta 0:00:17\n",
            "   ----------------------- ---------------- 114.4/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 114.7/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 115.0/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 115.4/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 115.7/198.6 MB 5.3 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 116.0/198.6 MB 5.4 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 116.3/198.6 MB 5.4 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 116.6/198.6 MB 5.4 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 116.8/198.6 MB 5.4 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 117.1/198.6 MB 5.4 MB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 117.5/198.6 MB 5.4 MB/s eta 0:00:15\n",
            "   ----------------------- ---------------- 117.7/198.6 MB 5.7 MB/s eta 0:00:15\n",
            "   ----------------------- ---------------- 118.0/198.6 MB 6.2 MB/s eta 0:00:14\n",
            "   ----------------------- ---------------- 118.3/198.6 MB 6.2 MB/s eta 0:00:13\n",
            "   ----------------------- ---------------- 118.6/198.6 MB 6.2 MB/s eta 0:00:13\n",
            "   ----------------------- ---------------- 118.9/198.6 MB 6.3 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 119.3/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 119.5/198.6 MB 6.5 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 119.9/198.6 MB 6.5 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 120.2/198.6 MB 6.5 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 120.5/198.6 MB 6.5 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 120.6/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 120.9/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 121.3/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 121.6/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 121.9/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 122.2/198.6 MB 6.4 MB/s eta 0:00:13\n",
            "   ------------------------ --------------- 122.5/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------ --------------- 122.8/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------ --------------- 123.1/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------ --------------- 123.4/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------ --------------- 123.8/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------ --------------- 124.1/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 124.4/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 124.7/198.6 MB 6.3 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 125.0/198.6 MB 6.3 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 125.3/198.6 MB 6.4 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 125.6/198.6 MB 6.3 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 125.9/198.6 MB 6.3 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 126.0/198.6 MB 6.3 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 126.1/198.6 MB 6.0 MB/s eta 0:00:13\n",
            "   ------------------------- -------------- 126.4/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 126.7/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 127.0/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 127.4/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 127.7/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 128.0/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 128.3/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 128.6/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   ------------------------- -------------- 128.9/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 129.2/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 129.6/198.6 MB 6.1 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 129.9/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 130.2/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 130.5/198.6 MB 6.2 MB/s eta 0:00:12\n",
            "   -------------------------- ------------- 130.8/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 131.1/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 131.4/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 131.7/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 132.0/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 132.3/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 132.7/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 133.0/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 133.3/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 133.7/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   -------------------------- ------------- 134.0/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 134.2/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 134.5/198.6 MB 6.2 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 134.6/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 134.9/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 135.2/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 135.5/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 135.9/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 136.1/198.6 MB 6.1 MB/s eta 0:00:11\n",
            "   --------------------------- ------------ 136.4/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 136.7/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 137.1/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 137.4/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 137.7/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 138.0/198.6 MB 6.3 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 138.3/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 138.6/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   --------------------------- ------------ 139.0/198.6 MB 6.3 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 139.3/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 139.6/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 139.9/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 140.2/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 140.6/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 140.9/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 141.2/198.6 MB 6.4 MB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 141.5/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 141.8/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 142.1/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 142.5/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 142.8/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 143.1/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 143.4/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 143.7/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 144.1/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 144.4/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 144.7/198.6 MB 6.4 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 145.0/198.6 MB 6.5 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 145.3/198.6 MB 6.5 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 145.6/198.6 MB 6.6 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 145.9/198.6 MB 6.5 MB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 146.2/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 146.5/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 146.8/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 147.2/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 147.4/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 147.8/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 148.0/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 148.4/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 148.7/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 149.0/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 149.2/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 149.6/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 149.9/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 150.3/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 150.6/198.6 MB 6.6 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 150.9/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 151.2/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 151.5/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 151.8/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 152.1/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 152.4/198.6 MB 6.5 MB/s eta 0:00:08\n",
            "   ------------------------------ --------- 152.8/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 153.1/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 153.4/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 153.7/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 154.0/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 154.3/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 154.6/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 155.0/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 155.3/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 155.6/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 155.9/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 156.2/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 156.5/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 156.9/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 157.2/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 157.5/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 157.8/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 158.1/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 158.4/198.6 MB 6.5 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 158.7/198.6 MB 6.6 MB/s eta 0:00:07\n",
            "   -------------------------------- ------- 159.0/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 159.4/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 159.7/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 160.0/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 160.3/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 160.6/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 160.9/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 161.2/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 161.5/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 161.8/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 162.1/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 162.4/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 162.7/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 163.1/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 163.3/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 163.7/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 164.0/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 164.3/198.6 MB 6.6 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 164.6/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 164.9/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 165.2/198.6 MB 6.5 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 165.4/198.6 MB 6.4 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 165.7/198.6 MB 6.4 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 166.0/198.6 MB 6.4 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 166.3/198.6 MB 6.4 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 166.7/198.6 MB 6.4 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 167.0/198.6 MB 6.5 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 167.1/198.6 MB 6.4 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 167.2/198.6 MB 6.2 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 167.5/198.6 MB 6.2 MB/s eta 0:00:06\n",
            "   --------------------------------- ------ 167.8/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 168.1/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 168.4/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 168.8/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 169.1/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 169.4/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 169.7/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 170.1/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 170.3/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 170.7/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 171.0/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 171.3/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 171.6/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 172.0/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 172.2/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 172.6/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 172.9/198.6 MB 6.3 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 173.2/198.6 MB 6.2 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 173.5/198.6 MB 6.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 173.8/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 174.2/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 174.4/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 174.7/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 175.1/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 175.4/198.6 MB 6.2 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 175.7/198.6 MB 6.4 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 176.0/198.6 MB 6.4 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 176.4/198.6 MB 6.4 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 176.6/198.6 MB 6.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 176.9/198.6 MB 6.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 177.2/198.6 MB 6.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 177.6/198.6 MB 6.5 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 177.9/198.6 MB 6.5 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 178.2/198.6 MB 6.6 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 178.5/198.6 MB 6.6 MB/s eta 0:00:04\n",
            "   ------------------------------------ --- 178.8/198.6 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 179.1/198.6 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 179.5/198.6 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 179.7/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 180.0/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 180.3/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 180.7/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 181.0/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 181.3/198.6 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 181.6/198.6 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 181.9/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 182.3/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 182.5/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 182.8/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 183.1/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 183.5/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 183.8/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 184.1/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 184.4/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 184.7/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 185.0/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 185.3/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 185.6/198.6 MB 6.5 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 185.9/198.6 MB 6.5 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 186.2/198.6 MB 6.5 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 186.4/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 186.6/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 186.9/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 187.2/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 187.5/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 187.8/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 188.1/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 188.4/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 188.7/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 189.1/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 189.4/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 189.7/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 190.0/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 190.3/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 190.6/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 190.9/198.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 191.3/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 191.6/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 191.9/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 192.2/198.6 MB 6.3 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 192.5/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 192.8/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 193.1/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 193.4/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  193.8/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  194.1/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  194.4/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  194.7/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  195.0/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  195.3/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  195.7/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  196.0/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  196.3/198.6 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  196.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  196.9/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  197.3/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  197.4/198.6 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  197.4/198.6 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  197.4/198.6 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  197.4/198.6 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  198.6/198.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 198.6/198.6 MB 4.1 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.3/1.2 MB 10.2 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 0.6/1.2 MB 7.9 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.0/1.2 MB 6.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.2/1.2 MB 6.7 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: typing-extensions, torch, torchvision\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "Successfully installed torch-2.2.1 torchvision-0.17.1 typing-extensions-4.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, target):\n",
        "        embeds = self.embedding(target)\n",
        "        out = self.linear(embeds)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate training samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>proces however afforded means ascertaining dim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>never occurred fumbling might mere mistake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>left hand gold snuff box capered hil cutting m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lovely spring looked windsor terrace sixteen f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>finding nothing else even gold superintendent ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  proces however afforded means ascertaining dim...\n",
              "1         never occurred fumbling might mere mistake\n",
              "2  left hand gold snuff box capered hil cutting m...\n",
              "3  lovely spring looked windsor terrace sixteen f...\n",
              "4  finding nothing else even gold superintendent ..."
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_c=pd.read_csv('preprocessed_data.csv')\n",
        "df_c=df_c.drop(columns=['id','author'],axis=0)\n",
        "df_c.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_np=df_c.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['proces however afforded means ascertaining dimensions dungeon might make circuit return point whence set without aware fact perfectly uniform seemed wal'],\n",
              "       ['never occurred fumbling might mere mistake'],\n",
              "       ['left hand gold snuff box capered hil cutting manner fantastic steps took snuff incessantly air greatest possible self satisfaction'],\n",
              "       ...,\n",
              "       ['mais il faut agir say frenchman never faints outright'],\n",
              "       ['item news like strikes us coolly received'],\n",
              "       ['laid gnarled claw shoulder seemed shaking altogether mirth']],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_training_data(corpus, window_size):\n",
        "    data = []\n",
        "    for sentence in corpus:\n",
        "        tokens = sentence.split()\n",
        "        for i, target_word in enumerate(tokens):\n",
        "            for j in range(i - window_size, i + window_size + 1):\n",
        "                if j != i and j >= 0 and j < len(tokens):\n",
        "                    context_word = tokens[j]\n",
        "                    data.append((target_word, context_word))\n",
        "    return data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "window_size = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for sentence in df_np.flatten():\n",
        "    if isinstance(sentence, str):\n",
        "        corpus.append(sentence)\n",
        "    else:\n",
        "        corpus.append(str(sentence))\n",
        "\n",
        "training_data = generate_training_data(corpus, window_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = list(set([word for sentence in corpus for word in sentence.split()]))\n",
        "vocab_size = len(vocab)\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SkipGram(vocab_size, embedding_dim)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_values = []\n",
        "accuracy_values = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    \n",
        "    for target_word, context_word in training_data:\n",
        "\n",
        "        target = Variable(torch.LongTensor([word_to_idx[target_word]]))\n",
        "        context = Variable(torch.LongTensor([word_to_idx[context_word]]))\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(target)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(output, context)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        correct_predictions += (predicted == context).sum().item()\n",
        "        total_predictions += context.size(0)\n",
        "\n",
        "    # Compute epoch loss and accuracy\n",
        "    epoch_loss = total_loss / len(training_data)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Append loss and accuracy values\n",
        "    loss_values.append(epoch_loss)\n",
        "    accuracy_values.append(epoch_accuracy)\n",
        "\n",
        "    # Print the average loss and accuracy for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy & loss Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss\n",
        "plt.plot(loss_values)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(accuracy_values)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
