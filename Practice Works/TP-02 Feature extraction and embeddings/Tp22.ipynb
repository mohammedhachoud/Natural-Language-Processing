{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11f7bcb",
   "metadata": {},
   "source": [
    "# Fiche TP N° 02: Feature extraction and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9662dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccbee45",
   "metadata": {},
   "source": [
    "### A. Préparation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f9e7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>this proces however afforded me no means of as...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>i could have fancied while i looked at it that...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>the lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>mais il faut agir that is to say a frenchman n...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>for an item of news like this it strikes us it...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>he laid a gnarled claw on my shoulder and it s...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "0      id26305  this proces however afforded me no means of as...    EAP\n",
       "1      id17569  it never once occurred to me that the fumbling...    HPL\n",
       "2      id11008  in his left hand was a gold snuff box from whi...    EAP\n",
       "3      id27763  how lovely is spring as we looked from windsor...    MWS\n",
       "4      id12958  finding nothing else not even gold the superin...    HPL\n",
       "...        ...                                                ...    ...\n",
       "19574  id17718  i could have fancied while i looked at it that...    EAP\n",
       "19575  id08973  the lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  mais il faut agir that is to say a frenchman n...    EAP\n",
       "19577  id17513  for an item of news like this it strikes us it...    EAP\n",
       "19578  id00393  he laid a gnarled claw on my shoulder and it s...    HPL\n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('out.csv')\n",
    "data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f3f87",
   "metadata": {},
   "source": [
    "### B. Encodage de la variable à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a2c53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>this proces however afforded me no means of as...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>i could have fancied while i looked at it that...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>the lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>mais il faut agir that is to say a frenchman n...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>for an item of news like this it strikes us it...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>he laid a gnarled claw on my shoulder and it s...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  this proces however afforded me no means of as...    EAP   \n",
       "1      id17569  it never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  in his left hand was a gold snuff box from whi...    EAP   \n",
       "3      id27763  how lovely is spring as we looked from windsor...    MWS   \n",
       "4      id12958  finding nothing else not even gold the superin...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  i could have fancied while i looked at it that...    EAP   \n",
       "19575  id08973  the lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  mais il faut agir that is to say a frenchman n...    EAP   \n",
       "19577  id17513  for an item of news like this it strikes us it...    EAP   \n",
       "19578  id00393  he laid a gnarled claw on my shoulder and it s...    HPL   \n",
       "\n",
       "       author_encoded  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   2  \n",
       "4                   1  \n",
       "...               ...  \n",
       "19574               0  \n",
       "19575               0  \n",
       "19576               0  \n",
       "19577               0  \n",
       "19578               1  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['author_encoded'] = le.fit_transform(data['author'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270c6ad",
   "metadata": {},
   "source": [
    "### C. Construction des bases d’entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd0c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'].values, \n",
    "                                                    data['author_encoded'].values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=33,\n",
    "                                                    stratify = data['author_encoded'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec064f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.349869118304284\n",
      "40.34729315628192\n"
     ]
    }
   ],
   "source": [
    "print(100*y_train.tolist().count(0)/(len(y_train)))\n",
    "print(100*y_test.tolist().count(0)/(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903ea3a",
   "metadata": {},
   "source": [
    "### D. Méthodes de vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58962e5",
   "metadata": {},
   "source": [
    "##### 1. Utiliser la méthode de fréquence lexicale et one-hot encoding pour vectoriser le dataset d’entrainement et du test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dffb0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# création d'un objet CountVectorizer pour effectuer la fréquence lexicale et l'encodage one-hot \n",
    "# (\n",
    "#    si binary=False => fréquence lexicale\n",
    "#    si binary=True => one-hot encoding\n",
    "#)\n",
    "vectorizer = CountVectorizer(binary=False,analyzer= 'word', stop_words='english')\n",
    "vectorizer_onehot = CountVectorizer(binary=True , analyzer= 'word', stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "vectorizer_onehot.fit(X_train)\n",
    "\n",
    "train_fl = vectorizer.transform(X_train)\n",
    "test_fl = vectorizer.transform(X_test)\n",
    "\n",
    "train_oneh = vectorizer_onehot.transform(X_train)\n",
    "test_oneh = vectorizer_onehot.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "055508c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abasement</th>\n",
       "      <th>abashed</th>\n",
       "      <th>abashment</th>\n",
       "      <th>...</th>\n",
       "      <th>zobnarian</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zoilus</th>\n",
       "      <th>zokar</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zory</th>\n",
       "      <th>zubmizion</th>\n",
       "      <th>zuro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15658</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15659</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15662</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15663 rows × 24463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ab  aback  abandon  abandoned  abandoning  abandonment  abaout  \\\n",
       "0       0      0        0          0           0            0       0   \n",
       "1       0      0        0          0           0            0       0   \n",
       "2       0      0        0          0           0            0       0   \n",
       "3       0      0        0          0           0            0       0   \n",
       "4       0      0        0          0           0            0       0   \n",
       "...    ..    ...      ...        ...         ...          ...     ...   \n",
       "15658   0      0        0          0           0            0       0   \n",
       "15659   0      0        0          0           0            0       0   \n",
       "15660   0      0        0          0           0            0       0   \n",
       "15661   0      0        0          0           0            0       0   \n",
       "15662   0      0        0          0           0            0       0   \n",
       "\n",
       "       abasement  abashed  abashment  ...  zobnarian  zodiac  zodiacal  \\\n",
       "0              0        0          0  ...          0       0         0   \n",
       "1              0        0          0  ...          0       0         0   \n",
       "2              0        0          0  ...          0       0         0   \n",
       "3              0        0          0  ...          0       0         0   \n",
       "4              0        0          0  ...          0       0         0   \n",
       "...          ...      ...        ...  ...        ...     ...       ...   \n",
       "15658          0        0          0  ...          0       0         0   \n",
       "15659          0        0          0  ...          0       0         0   \n",
       "15660          0        0          0  ...          0       0         0   \n",
       "15661          0        0          0  ...          0       0         0   \n",
       "15662          0        0          0  ...          0       0         0   \n",
       "\n",
       "       zoilus  zokar  zone  zones  zory  zubmizion  zuro  \n",
       "0           0      0     0      0     0          0     0  \n",
       "1           0      0     0      0     0          0     0  \n",
       "2           0      0     0      0     0          0     0  \n",
       "3           0      0     0      0     0          0     0  \n",
       "4           0      0     0      0     0          0     0  \n",
       "...       ...    ...   ...    ...   ...        ...   ...  \n",
       "15658       0      0     0      0     0          0     0  \n",
       "15659       0      0     0      0     0          0     0  \n",
       "15660       0      0     0      0     0          0     0  \n",
       "15661       0      0     0      0     0          0     0  \n",
       "15662       0      0     0      0     0          0     0  \n",
       "\n",
       "[15663 rows x 24463 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array_cv = train_cv.toarray()\n",
    "df = pd.DataFrame(data=count_array_cv,columns = vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f577661",
   "metadata": {},
   "source": [
    "##### 2 et 3. Entrainer un modèle de vectorisation TF-IDF sur la partie d’entrainement et vectorisez-le. (et de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845164c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# création d'un objet TfidfVectorizer pour effectuer la vectorisation TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer= 'word', stop_words='english')\n",
    "\n",
    "# ajustement du vectorizer sur le texte d'entraînement\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# transformation du texte d'entraînement et de test en vecteurs TF-IDF\n",
    "train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a03e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abasement</th>\n",
       "      <th>abashed</th>\n",
       "      <th>abashment</th>\n",
       "      <th>...</th>\n",
       "      <th>zobnarian</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zoilus</th>\n",
       "      <th>zokar</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zory</th>\n",
       "      <th>zubmizion</th>\n",
       "      <th>zuro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15658</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15662</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15663 rows × 24463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ab  aback  abandon  abandoned  abandoning  abandonment  abaout  \\\n",
       "0      0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "1      0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "2      0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "3      0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "4      0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "...    ...    ...      ...        ...         ...          ...     ...   \n",
       "15658  0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "15659  0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "15660  0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "15661  0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "15662  0.0    0.0      0.0        0.0         0.0          0.0     0.0   \n",
       "\n",
       "       abasement  abashed  abashment  ...  zobnarian  zodiac  zodiacal  \\\n",
       "0            0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "1            0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "2            0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "3            0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "4            0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "...          ...      ...        ...  ...        ...     ...       ...   \n",
       "15658        0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "15659        0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "15660        0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "15661        0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "15662        0.0      0.0        0.0  ...        0.0     0.0       0.0   \n",
       "\n",
       "       zoilus  zokar  zone  zones  zory  zubmizion  zuro  \n",
       "0         0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "1         0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "2         0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "3         0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "4         0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "...       ...    ...   ...    ...   ...        ...   ...  \n",
       "15658     0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "15659     0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "15660     0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "15661     0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "15662     0.0    0.0   0.0    0.0   0.0        0.0   0.0  \n",
       "\n",
       "[15663 rows x 24463 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array_tfidf = train_tfidf.toarray()\n",
    "df = pd.DataFrame(data=count_array_tfidf,columns = tfidf_vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899449fc",
   "metadata": {},
   "source": [
    "### E. Entrainement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee183f22",
   "metadata": {},
   "source": [
    "#### 1. Créer trois modèles du type MLPClassifier. (Vous pouvez changer l’algorithme d’apprentissage : utiliser les autres algorithmes de scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5d257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Modèle 1 : 1 couche cachée avec 100 neurones\n",
    "model1 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, solver='adam', random_state=1)\n",
    "\n",
    "# Modèle 2 : 2 couches cachées avec 50 et 25 neurones, respectivement\n",
    "model2 = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=200, solver='adam', random_state=1)\n",
    "\n",
    "# Modèle 3 : 3 couches cachées avec 100, 50 et 25 neurones, respectivement\n",
    "model3 = MLPClassifier(hidden_layer_sizes=(100, 50, 25), max_iter=200, solver='adam', random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0f53f",
   "metadata": {},
   "source": [
    "#### 2,3 et 4. \n",
    " - Entrainer ces trois modèles sur les trois représentations vectorielles \n",
    " - Prédire les classes en appliquant les trois modèles sur les trois représentations d’entrainement.\n",
    " - Afficher le rapport de classification en utilisant les mesures de performance (accuracy, precision, recall…).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "104881fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n",
      "Model 2\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n",
      "Model 3\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6320\n",
      "           1       1.00      1.00      1.00      4508\n",
      "           2       1.00      1.00      1.00      4835\n",
      "\n",
      "    accuracy                           1.00     15663\n",
      "   macro avg       1.00      1.00      1.00     15663\n",
      "weighted avg       1.00      1.00      1.00     15663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# création des modèles avec différentes architectures de couches cachées\n",
    "models = [\n",
    "    model1,\n",
    "    model2,\n",
    "    model3\n",
    "]\n",
    "\n",
    "# entrainement des modèles sur les différentes représentations\n",
    "representations = [(train_cv, test_cv),(train_tfidf, test_tfidf)]\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}\")\n",
    "    for j, rep in enumerate(representations):\n",
    "        \n",
    "        # entraînement du modèle\n",
    "        model.fit(rep[0], y_train)\n",
    "        \n",
    "        # prédiction sur le jeu de train\n",
    "        y_pred = model.predict(rep[0])\n",
    "        \n",
    "        # évaluation de la performance du modèle\n",
    "        \n",
    "        print(f\"Representation {j+1}:\")\n",
    "        print(classification_report(y_train, y_pred))\n",
    "\n",
    "        \n",
    "        # save the model to disk\n",
    "        filename = f'models/finalized_model{i+1}.{j+1}.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "647d01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the model from disk\n",
    "#filename = \"models/finalized_model1.2.sav\"\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#y_pred = loaded_model.predict(train_cv)\n",
    "\n",
    "#result = accuracy_score(y_pred, y_train)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a0f95",
   "metadata": {},
   "source": [
    "### F. Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc323269",
   "metadata": {},
   "source": [
    "##### Pour Model1 et La Representation 1 (CountVect ) et 2 (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2a6a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Pour Model N°1 et La Representation 1 (CountVect ) et 2 (TF-IDF)\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1511\n",
      "           1       0.70      0.73      0.72      1084\n",
      "           2       0.77      0.71      0.74      1321\n",
      "\n",
      "    accuracy                           0.73      3916\n",
      "   macro avg       0.73      0.73      0.73      3916\n",
      "weighted avg       0.73      0.73      0.73      3916\n",
      "\n",
      "Model 1 prediction time: 0.009311914443969727 seconds\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1532\n",
      "           1       0.73      0.78      0.76      1054\n",
      "           2       0.80      0.73      0.77      1330\n",
      "\n",
      "    accuracy                           0.77      3916\n",
      "   macro avg       0.77      0.77      0.76      3916\n",
      "weighted avg       0.77      0.77      0.77      3916\n",
      "\n",
      "Model 1 prediction time: 0.0 seconds\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Pour Model N°2 et La Representation 1 (CountVect ) et 2 (TF-IDF)\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      1549\n",
      "           1       0.72      0.73      0.73      1104\n",
      "           2       0.76      0.73      0.74      1263\n",
      "\n",
      "    accuracy                           0.74      3916\n",
      "   macro avg       0.74      0.74      0.74      3916\n",
      "weighted avg       0.74      0.74      0.74      3916\n",
      "\n",
      "Model 2 prediction time: 0.01564788818359375 seconds\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1501\n",
      "           1       0.76      0.76      0.76      1129\n",
      "           2       0.80      0.75      0.77      1286\n",
      "\n",
      "    accuracy                           0.77      3916\n",
      "   macro avg       0.77      0.77      0.77      3916\n",
      "weighted avg       0.77      0.77      0.77      3916\n",
      "\n",
      "Model 2 prediction time: 0.0 seconds\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Pour Model N°3 et La Representation 1 (CountVect ) et 2 (TF-IDF)\n",
      "Representation 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1595\n",
      "           1       0.75      0.77      0.76      1092\n",
      "           2       0.77      0.76      0.77      1229\n",
      "\n",
      "    accuracy                           0.77      3916\n",
      "   macro avg       0.77      0.77      0.77      3916\n",
      "weighted avg       0.77      0.77      0.77      3916\n",
      "\n",
      "Model 3 prediction time: 0.0 seconds\n",
      "Representation 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      1602\n",
      "           1       0.71      0.81      0.76       993\n",
      "           2       0.80      0.73      0.77      1321\n",
      "\n",
      "    accuracy                           0.77      3916\n",
      "   macro avg       0.76      0.77      0.77      3916\n",
      "weighted avg       0.77      0.77      0.77      3916\n",
      "\n",
      "Model 3 prediction time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for i in range(3):\n",
    "    print('\\n\\n************************************************************')\n",
    "    print(f\"Pour Model N°{i+1} et La Representation 1 (CountVect ) et 2 (TF-IDF)\")\n",
    "    representations = [test_cv, test_tfidf]\n",
    "\n",
    "    for j, rep in enumerate(representations):\n",
    "        print(f\"Representation {j+1}:\")\n",
    "\n",
    "        # load the model from disk\n",
    "        filename = f\"models/finalized_model{i+1}.{j+1}.sav\"\n",
    "        loaded_model = pickle.load(open(filename, 'rb'))\n",
    "        \n",
    "        # Model prediction time\n",
    "        start_time = time.time()\n",
    "        y_pred = loaded_model.predict(rep)\n",
    "        end_time = time.time()\n",
    "\n",
    "        result = classification_report(y_pred, y_test)\n",
    "        print(result)\n",
    "        print(f\"Model {i+1} prediction time: {(end_time - start_time)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20972a",
   "metadata": {},
   "source": [
    "### G. Vectorisations basées sur les embeddings de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562d13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
